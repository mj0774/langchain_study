{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a047674",
   "metadata": {},
   "source": [
    "### ëª©ì \n",
    "- LLMì´ ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆë„ë¡ ì •ë³´ì™€ ë„êµ¬ë¥¼ ì ì ˆí•œ í˜•ì‹ìœ¼ë¡œ ì œê³µí•˜ëŠ” ë™ì  ì‹œìŠ¤í…œ êµ¬ì¶•"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29bc611",
   "metadata": {},
   "source": [
    "#### ì»¨í…ìŠ¤íŠ¸ ì—”ì§€ë‹ˆì–´ë§ vs í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§\n",
    "| êµ¬ë¶„    | í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§                 | ì»¨í…ìŠ¤íŠ¸ ì—”ì§€ë‹ˆì–´ë§                                        |\n",
    "| ----- | -------------------------- | ------------------------------------------------- |\n",
    "| ì´ˆì     | í•œ ë²ˆì˜ ì…ë ¥ë¬¸ ì„¤ê³„                | ì „ì²´ ëŒ€í™”Â·ìƒíƒœÂ·í™˜ê²½ì˜ êµ¬ì¡° ì„¤ê³„                                |\n",
    "| ë‹¨ìœ„    | ë¬¸ìì—´ prompt                 | êµ¬ì¡°í™”ëœ context object                               |\n",
    "| ì ‘ê·¼ ë°©ì‹ | â€œì–´ë–»ê²Œ ë¬¼ì–´ë³¼ê¹Œ?â€                | â€œë¬´ì—‡ì„ ì•Œê³ , ì–´ë–¤ ìƒí™©ì—ì„œ ëŒ€ë‹µí•´ì•¼ í•˜ë‚˜?â€                        |\n",
    "| ì£¼ìš” ê¸°ìˆ  | few-shot, CoT, role prompt | context_schema, dynamic_prompt, middleware, state |\n",
    "| ê²°ê³¼    | ì¦‰ì‹œ í’ˆì§ˆ í–¥ìƒ                   | ì§€ì†ì  ì¼ê´€ì„±, ê°œì¸í™”, ë©€í‹°í„´ ì •í™•ë„                             |\n",
    "| ë¹„ìœ     | ë¬¸ì¥ ê¸°ìˆ                       | ì‹œìŠ¤í…œ ì„¤ê³„                                            |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd60c17",
   "metadata": {},
   "source": [
    "#### ì»¨í…ìŠ¤íŠ¸ ì¢…ë¥˜\n",
    "| ì»¨í…ìŠ¤íŠ¸ ì¢…ë¥˜                | ëª©ì                                       | ì–´ë””ì— ì €ì¥ë˜ë‚˜   | ì§€ì† ì‹œê°„                |\n",
    "| ---------------------- | --------------------------------------- | ---------- | -------------------- |\n",
    "| **Model Context**      | ëª¨ë¸ì—ê²Œ ì£¼ëŠ” ì¼ì‹œì  ì •ë³´ (í”„ë¡¬í”„íŠ¸, ë©”ì‹œì§€, íˆ´ ëª©ë¡ ë“±)      | ìš”ì²­ ë‚´ë¶€      | ğŸ”¹ì§§ìŒ (í•œ ë²ˆ í˜¸ì¶œìš©)       |\n",
    "| **Tool Context**       | íˆ´ í•¨ìˆ˜ê°€ ì½ê³  ì“¸ ìˆ˜ ìˆëŠ” í™˜ê²½(context/state/store) | Runtime ê°ì²´ | ğŸ”¸ì¤‘ê°„ (ì„¸ì…˜ ë‚´ ìœ ì§€)       |\n",
    "| **Life-cycle Context** | ì‹¤í–‰ ì „í›„ ê°ì‹œÂ·ì œì–´ìš© (ë¯¸ë“¤ì›¨ì–´, ìš”ì•½, ê²€ì—´ ë“±)           | ë¯¸ë“¤ì›¨ì–´ ê³„ì¸µ    | ğŸ”¸ì§€ì† (ì—¬ëŸ¬ í˜¸ì¶œ ê°„ ìœ ì§€ ê°€ëŠ¥) |\n",
    "\n",
    "- Model Context: ë§¤ í˜¸ì¶œë§ˆë‹¤ ìƒˆë¡œ ìƒì„± (Transient)\n",
    "- Tool/Life-cycle Context: ì‹¤í–‰ ì¤‘ í˜¹ì€ ì¥ê¸°ì ìœ¼ë¡œ ìœ ì§€ (Persistent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff02a5c",
   "metadata": {},
   "source": [
    "#### ì»¨í…ìŠ¤íŠ¸ ë°ì´í„° êµ¬ì„±\n",
    "- context: í˜„ì¬ ì‚¬ìš©ìë‚˜ í™˜ê²½ê°™ì€ ê³ ì • ì •ë³´ -> ì¡°íšŒ/ì°¸ê³ ë§Œ í•˜ê³  ë¶ˆë³€ì˜ ì„±ì§ˆ\n",
    "    - ex) user_id, language, timezone\n",
    "- state: ëŒ€í™” ì¤‘ ì ê¹ ìœ ì§€ë˜ëŠ” ë‹¨ê¸° ë©”ëª¨ë¦¬ -> ì§„í–‰ ìƒí™©ì„ stepë§ˆë‹¤ ì €ì¥í•˜ê³  ê°±ì‹ ë˜ëŠ” ì„±ì§ˆ\n",
    "    - ex) ì§ì „ ë©”ì‹œì§€, ì—…ë¡œë“œ íŒŒì¼ ìš”ì•½\n",
    "- store: ì¥ê¸° ë©”ëª¨ë¦¬\n",
    "    - ex) ì‚¬ìš©ì ì„ í˜¸, ê³¼ê±° ëŒ€í™” ìš”ì•½, ì˜êµ¬ ê¸°ë¡"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763ad288",
   "metadata": {},
   "source": [
    "#### ê° ì»¨í…ìŠ¤íŠ¸ ë³„ë¡œ ë‹¤ë£¨ëŠ” ë°ì´í„° ì†ŒìŠ¤\n",
    "| ì»¨íŠ¸ë¡¤ ê³„ì¸µ                 | ì½ëŠ” ë°ì´í„°                      | ì“°ëŠ” ë°ì´í„°          | ì£¼ìš” ì ‘ê·¼ ë°©ì‹                                                 | ë¹„ê³           |\n",
    "| ---------------------- | --------------------------- | --------------- | -------------------------------------------------------- | ----------- |\n",
    "| **Model Context**      | `context`, `state`, `store` | âŒ (ì½ê¸° ì¤‘ì‹¬)       | `request.context`, `request.state`, `request.store`      | ëª¨ë¸ í˜¸ì¶œ ì§ì „/ì§í›„ |\n",
    "| **Tool Context**       | `state`, `store`            | âœ… (Commandë¡œ ê°±ì‹ ) | `runtime.state`, `runtime.store`                         | íˆ´ í•¨ìˆ˜ ë‚´ ì‹¤í–‰   |\n",
    "| **Life-cycle Context** | `state`, `store`            | âœ… (ìš”ì•½/ê¸°ë¡)       | `before_model`, `after_model`, `SummarizationMiddleware` | ëŒ€í™” ê´€ë¦¬/ì••ì¶•    |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8027d369",
   "metadata": {},
   "source": [
    "#### Model Context ì¡°ì‘ ê¸°ë²• - System prompt\n",
    "- @dynamic_prompt\n",
    "    - ì‹¤í–‰ ì‹œì ì— state, runtime.context, runtime.storeë¥¼ ì½ì–´ system promptë¥¼ ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbe9056a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â–¶ ì§§ì€ ëŒ€í™”:\n",
      "1\n",
      "ì¸ê³µì§€ëŠ¥(Artificial Intelligence, AI)ì€ ì»´í“¨í„° ì‹œìŠ¤í…œì´ë‚˜ ê¸°ê³„ê°€ ì¸ê°„ì²˜ëŸ¼ ì‚¬ê³ , í•™ìŠµ, ë¬¸ì œ í•´ê²°, ì˜ì‚¬ê²°ì • ë“±ì˜ ì¼ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ê¸°ìˆ ì„ ë§í•©ë‹ˆë‹¤. ì¸ê³µì§€ëŠ¥ì€ ì—¬ëŸ¬ ê°€ì§€ í•˜ìœ„ ë¶„ì•¼ë¡œ ë‚˜ëˆŒ ìˆ˜ ìˆìœ¼ë©°, ì£¼ë¡œ ë‹¤ìŒê³¼ ê°™ì€ ì˜ì—­ì„ í¬í•¨í•©ë‹ˆë‹¤.\n",
      "\n",
      "1. **ê¸°ê³„ í•™ìŠµ (Machine Learning)**: ì´ ë¶„ì•¼ëŠ” ì»´í“¨í„°ê°€ ë°ì´í„°ë¥¼ í†µí•´ íŒ¨í„´ì„ ì¸ì‹í•˜ê³ , ê²½í—˜ì„ í†µí•´ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ë°©ë²•ì— ì¤‘ì ì„ ë‘¡ë‹ˆë‹¤. ê¸°ê³„ í•™ìŠµì˜ í•œ í˜•íƒœì¸ ì‹¬ì¸µ í•™ìŠµ(Deep Learning)ì€ ì¸ê³µ ì‹ ê²½ë§ì„ ì‚¬ìš©í•˜ì—¬ ë” ë³µì¡í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.\n",
      "\n",
      "2. **ìì—°ì–´ ì²˜ë¦¬ (Natural Language Processing, NLP)**: ì´ëŠ” ì»´í“¨í„°ì™€ ì¸ê°„ ì–¸ì–´ ê°„ì˜ ìƒí˜¸ì‘ìš©ì„ ë‹¤ë£¨ëŠ” ë¶„ì•¼ë¡œ, ì˜ˆë¥¼ ë“¤ì–´ í…ìŠ¤íŠ¸ì˜ ì˜ë¯¸ë¥¼ ì´í•´í•˜ê³  ìƒì„±í•˜ê±°ë‚˜, ìŒì„±ì„ ì¸ì‹í•˜ëŠ” ê¸°ìˆ ì´ í¬í•¨ë©ë‹ˆë‹¤.\n",
      "\n",
      "3. **ì»´í“¨í„° ë¹„ì „ (Computer Vision)**: ì´ ë¶„ì•¼ëŠ” ì»´í“¨í„°ê°€ ì´ë¯¸ì§€ë¥¼ ì´í•´í•˜ê³  í•´ì„í•˜ëŠ” ë°©ë²•ì— ì£¼ëª©í•©ë‹ˆë‹¤. ì–¼êµ´ ì¸ì‹, ë¬¼ì²´ íƒì§€, ì´ë¯¸ì§€ ë¶„ë¥˜ ë“±ì˜ ê¸°ìˆ ì´ ì—¬ê¸°ì— í•´ë‹¹í•©ë‹ˆë‹¤.\n",
      "\n",
      "4. **ë¡œë³´í‹±ìŠ¤ (Robotics)**: ë¡œë´‡ì„ ì„¤ê³„í•˜ê³  ì œì–´í•˜ëŠ” ë¶„ì•¼ë¡œ, ì¸ê³µì§€ëŠ¥ì„ í™œìš©í•˜ì—¬ ë¡œë´‡ì´ í™˜ê²½ì„ ì¸ì‹í•˜ê³ , ì‘ì—…ì„ ìˆ˜í–‰í•˜ë©°, ììœ¨ì ìœ¼ë¡œ ì›€ì§ì´ëŠ” ëŠ¥ë ¥ì„ ê°–ì¶”ê²Œ í•©ë‹ˆë‹¤.\n",
      "\n",
      "5. **ì „ë¬¸ ì‹œìŠ¤í…œ (Expert Systems)**: íŠ¹ì • ë¶„ì•¼ì—ì„œ ì „ë¬¸ê°€ì˜ ê²°ì •ì„ ëª¨ë°©í•˜ëŠ” ì‹œìŠ¤í…œìœ¼ë¡œ, ì˜ë£Œ ì§„ë‹¨, ê¸ˆìœµ ë¶„ì„, ê¸°ìˆ  ì§€ì› ë“±ì—ì„œ í™œìš©ë©ë‹ˆë‹¤.\n",
      "\n",
      "ì¸ê³µì§€ëŠ¥ì€ ì´ë¯¸ ì—¬ëŸ¬ ë¶„ì•¼ì—ì„œ ë„ë¦¬ ì‚¬ìš©ë˜ê³  ìˆìœ¼ë©°, ê³ ê° ì„œë¹„ìŠ¤, ììœ¨ì£¼í–‰ì°¨, ì¶”ì²œ ì‹œìŠ¤í…œ, ì˜ë£Œ ì§„ë‹¨ ë“±ì˜ ë‹¤ì–‘í•œ ì‘ìš© ë¶„ì•¼ì— ì ìš©ë˜ê³  ìˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ì¸ê³µì§€ëŠ¥ì˜ ë°œì „ê³¼ ì‚¬ìš©ì—ëŠ” ìœ¤ë¦¬ì  ë¬¸ì œì™€ í•¨ê»˜ ì‚¬íšŒì  ì˜í–¥ë„ ìˆê¸° ë•Œë¬¸ì—, ì´ëŸ¬í•œ ì¸¡ë©´ë„ í•¨ê»˜ ê³ ë¯¼í•´ì•¼ í•©ë‹ˆë‹¤. \n",
      "\n",
      "â–¶ ê¸´ ëŒ€í™”:\n",
      "7\n",
      "ì¸ê³µì§€ëŠ¥(Artificial Intelligence, AI)ì€ ì¸ê°„ì˜ ì§€ëŠ¥ì„ ëª¨ë°©í•˜ê±°ë‚˜ ê¸°ëŠ¥í•˜ëŠ” ì»´í“¨í„° ì‹œìŠ¤í…œì´ë‚˜ í”„ë¡œê·¸ë¨ì„ ë§í•©ë‹ˆë‹¤. ë¬¸ì œ í•´ê²°, í•™ìŠµ, ì–¸ì–´ ì´í•´ ë“±ì˜ ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# state ì‚¬ìš© ì˜ˆì‹œ ì½”ë“œ\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import dynamic_prompt, ModelRequest\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "@dynamic_prompt\n",
    "def system_prompt_selector(request: ModelRequest) -> str:\n",
    "    \"\"\"\n",
    "    í˜„ì¬ ëŒ€í™” ê¸¸ì´ì— ë”°ë¼ system promptë¥¼ ìë™ ë³€ê²½í•œë‹¤.\n",
    "    - ë©”ì‹œì§€ê°€ ë§ìœ¼ë©´: ê°„ê²°í•˜ê²Œ\n",
    "    - ë©”ì‹œì§€ê°€ ì ìœ¼ë©´: ì¼ë°˜ ëª¨ë“œ\n",
    "    \"\"\"\n",
    "    # request.state[\"messages\"] ë¥¼ request.messages ë¡œ ì¤„ì—¬ì„œ ì ì„ ìˆ˜ ìˆë‹¤. -> ìµœì‹  ë²„ì „ ê¶Œì¥ì€ ì¶•ì•½ í˜•íƒœ\n",
    "    # message_count = len(request.messages)\n",
    "    message_count = len(request.state[\"messages\"])\n",
    "    print(len(request.state[\"messages\"]))\n",
    "    base = \"ë„ˆëŠ” ìœ ìš©í•œ ì–´ì‹œìŠ¤í„´íŠ¸ì´ë‹¤.\"\n",
    "    if message_count > 5:\n",
    "        base += \"\\nëŒ€í™”ê°€ ê¸¸ì–´ì¡Œìœ¼ë‹ˆ ê°„ê²°í•˜ê²Œ ë‹µë³€í•´ë¼.\"\n",
    "    else:\n",
    "        base += \"\\nìƒì„¸í•˜ê³  ì¹œì ˆí•˜ê²Œ ì„¤ëª…í•´ë¼.\"\n",
    "    return base\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=[],  \n",
    "    middleware=[system_prompt_selector]\n",
    ")\n",
    "\n",
    "conversation_short = {\"messages\": [{\"role\": \"user\", \"content\": \"ì¸ê³µì§€ëŠ¥ì´ ë­ì•¼?\"}]}\n",
    "conversation_long = {\"messages\": [{\"role\": \"user\", \"content\": \"ì¸ê³µì§€ëŠ¥ì´ ë­ì•¼?\"} for i in range(7)]}\n",
    "\n",
    "print(\"â–¶ ì§§ì€ ëŒ€í™”:\")\n",
    "result_short = agent.invoke(conversation_short)\n",
    "print(result_short[\"messages\"][-1].content, \"\\n\")\n",
    "\n",
    "print(\"â–¶ ê¸´ ëŒ€í™”:\")\n",
    "result_long = agent.invoke(conversation_long)\n",
    "print(result_long[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d7d6f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user id: u-001\n",
      "ì¸ê³µì§€ëŠ¥ì€ ì‚¬ëŒë“¤ì´ í•˜ëŠ” ì¸ì§€ì ì¸ ì‘ì—…ì„ ì»´í“¨í„°ê°€ ìˆ˜í–‰í•  ìˆ˜ ìˆë„ë¡ ë§Œë“œëŠ” ê¸°ìˆ ì´ì•¼. ì—¬ê¸°ì—ëŠ” í•™ìŠµ, ë¬¸ì œ í•´ê²°, ì¶”ë¡ , ì–¸ì–´ ì´í•´ ë“±ì´ í¬í•¨ë¼. ì‰½ê²Œ ë§í•˜ë©´, ê¸°ê³„ê°€ ì‚¬ëŒì²˜ëŸ¼ ìƒê°í•˜ê³  í–‰ë™í•˜ë„ë¡ ë§Œë“œëŠ” ê±°ì•¼.\n"
     ]
    }
   ],
   "source": [
    "# contextì™€ store ì‚¬ìš© ì˜ˆì‹œ ì½”ë“œ\n",
    "\n",
    "import os\n",
    "from dataclasses import dataclass\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import dynamic_prompt, ModelRequest\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "@dataclass\n",
    "class Context:\n",
    "    user_id: str\n",
    "\n",
    "# ì¥ê¸° ìŠ¤í† ì–´ ì¤€ë¹„\n",
    "store = InMemoryStore()\n",
    "store.put((\"preferences\",), \"u-001\", {\"communication_style\": \"ë°˜ë§\"})\n",
    "\n",
    "# ë™ì  ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸: context.user_idë¡œ store ì¡°íšŒ\n",
    "@dynamic_prompt\n",
    "def store_aware_prompt(request: ModelRequest) -> str:\n",
    "    user_id = request.runtime.context.user_id # ëŸ°íƒ€ì„ì—ì„œ contextë¡œ ë“¤ì–´ì˜¨ user_id\n",
    "    print(\"user id:\", user_id)\n",
    "    item = request.runtime.store.get((\"preferences\",), user_id) # ì¥ê¸° ë©”ëª¨ë¦¬ì—ì„œ user_idë¡œ ì„ í˜¸ ê²€ìƒ‰\n",
    "    base = \"ë„ˆëŠ” ìœ ìš©í•œ ì¡°ìˆ˜ì´ë‹¤.\"\n",
    "    if item:\n",
    "        style = item.value.get(\"communication_style\", \"ê· í˜•ì¡íŒ ì–´íˆ¬\")\n",
    "        base += f\"\\nìœ ì €ì˜ ì„ í˜¸ë„ëŠ” {style} ì´ë‹¤.\"\n",
    "    return base\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=[],\n",
    "    middleware=[store_aware_prompt],\n",
    "    context_schema=Context,\n",
    "    store=store,\n",
    ")\n",
    "\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"ê°„ë‹¨íˆ ìš”ì•½í•´ì„œ ì¸ê³µì§€ëŠ¥ ì •ì˜í•´ì¤˜\"}]},\n",
    "    context=Context(user_id=\"u-001\"),\n",
    ")\n",
    "\n",
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb06dabf",
   "metadata": {},
   "source": [
    "#### Model Context ì¡°ì‘ ê¸°ë²• - Messages\n",
    "- @wrap_model_call\n",
    "    - ëª¨ë¸ì— ì‹¤ì œë¡œ ë“¤ì–´ê°€ëŠ” ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ë¥¼ ì¡°ì‘ -> ëª¨ë¸ ì…ë ¥ì„ ì§ì „ì— ë‹¤ë“¬ì–´ ì •í™•ë„, ì•ˆì „ì„±, í† í° íš¨ìœ¨ì„ ë†’ì¸ë‹¤.(ìš”ì•½, ì •ë¦¬, í•„í„°ë§, ì»¨í…ìŠ¤íŠ¸ ì£¼ì… ë“±)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aebb8535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìµœê·¼ ì—ëŸ¬ ë¡œê·¸ë¥¼ ë¶„ì„í•œ ê²°ê³¼, ì„œë¹„ìŠ¤ ì¥ì• ì˜ ì›ì¸ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
      "\n",
      "1. **ì ‘ì† ì§€ì—°**: íŠ¹ì • ì‹œê°„ëŒ€ì— ì„œë²„ì— ëŒ€í•œ ìš”ì²­ì´ ê¸‰ì¦í•˜ì—¬ ì§€ì—°ì´ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì´ëŠ” ì„œë²„ì˜ ë¦¬ì†ŒìŠ¤ ì´ˆê³¼ ì‚¬ìš©ìœ¼ë¡œ ì´ì–´ì¡ŒìŠµë‹ˆë‹¤.\n",
      "\n",
      "2. **ë„¤íŠ¸ì›Œí¬ ì¥ì• **: ë¡œê·¸ì— ë„¤íŠ¸ì›Œí¬ ì—°ê²° ì˜¤ë¥˜ê°€ ê¸°ë¡ë˜ì–´ ìˆì–´, ì´ë¡œ ì¸í•´ ì‚¬ìš©ìì˜ ìš”ì²­ì´ ì™„ë£Œë˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "3. **ë°ì´í„°ë² ì´ìŠ¤ ì˜¤ë¥˜**: ë°ì´í„°ë² ì´ìŠ¤ ì ‘ì† ì‹œë„ì—ì„œ ì‹œê°„ ì´ˆê³¼ê°€ ë°œìƒí•˜ì—¬, í•„ìš”í•œ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í•˜ëŠ” ë¬¸ì œê°€ ìˆì—ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "4. **ì• í”Œë¦¬ì¼€ì´ì…˜ ë²„ê·¸**: íŠ¹ì • ê¸°ëŠ¥ì—ì„œ ì˜ˆì™¸ê°€ ë°œìƒí•˜ê³  ë¡œê·¸ì— ìº¡ì²˜ë˜ì–´ ì˜¤ë¥˜ê°€ ë°˜ë³µì ìœ¼ë¡œ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì´ëŠ” ì½”ë“œì˜ ì¼ë¶€ ë¡œì§ ì˜¤ë¥˜ë¡œ ì¶”ì¸¡ë©ë‹ˆë‹¤.\n",
      "\n",
      "ì´ëŸ¬í•œ ë¬¸ì œë“¤ì€ ì‹œìŠ¤í…œì˜ ì„±ëŠ¥ê³¼ ì•ˆì •ì„±ì— ì˜í–¥ì„ ë¯¸ì³¤ìœ¼ë©°, ì¦‰ê°ì ì¸ í•´ê²°ì±…ì´ í•„ìš”í•©ë‹ˆë‹¤. ê° ì›ì¸ì„ ê°œì„ í•˜ê¸° ìœ„í•œ ì¡°ì¹˜ê°€ ìš”êµ¬ë©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# state ì‚¬ìš© ì˜ˆì‹œ ì½”ë“œ\n",
    "import os\n",
    "from typing import Callable, List, Dict, Any\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import wrap_model_call, ModelRequest, ModelResponse\n",
    "from langchain.agents import AgentState\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "class MyState(AgentState):\n",
    "    uploaded_files: List[Dict[str, Any]]\n",
    "\n",
    "@wrap_model_call\n",
    "def inject_file_context(\n",
    "    request: ModelRequest,\n",
    "    handler: Callable[[ModelRequest], ModelResponse]\n",
    ") -> ModelResponse:\n",
    "    \"\"\"ì´ ì„¸ì…˜ì—ì„œ ì‚¬ìš©ìê°€ ì—…ë¡œë“œí•œ íŒŒì¼ì— ëŒ€í•œ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì‚½ì…í•©ë‹ˆë‹¤.\"\"\"\n",
    "    uploaded_files_state: List[Dict[str, Any]] = request.state.get('uploaded_files', [])\n",
    "    \n",
    "    if uploaded_files_state:\n",
    "        file_description = [\n",
    "            f\"{f['name']} ({f['type']}): {f['summary']}\"\n",
    "            for f in uploaded_files_state\n",
    "        ]\n",
    "\n",
    "        file_context = (\n",
    "            \"ì´ ëŒ€í™”ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ íŒŒì¼:\\n\"\n",
    "            + \"\\n\".join(file_description)\n",
    "            + \"\\në‹µë³€í•  ë•Œ ì´ê²ƒì„ ì°¸ê³  ìë£Œë¡œ í™œìš©í•˜ì„¸ìš”.\"\n",
    "        )\n",
    "\n",
    "        augmented_messages = [\n",
    "            {'role': 'system', 'content': file_context},\n",
    "            *request.messages # ìŠ¤í”„ë ˆë“œ(unpack) ë¬¸ë²• -> request.messagesì„ í’€ì–´ì„œ ë’¤ì— ì´ì–´ë¶™ì„\n",
    "        ]\n",
    "\n",
    "        request = request.override(messages=augmented_messages) # ìˆ˜ì •í•œ messagesë¥¼ êµì²´í•œë‹¤.\n",
    "        # override()ë¥¼ ì¨ì•¼í•˜ëŠ” ì´ìœ ?\n",
    "        # ModelRequest ê°ì²´ëŠ” ë¶ˆë³€(immutable)ì´ë¼ì„œ request.messages=... ë¡œ ìˆ˜ì •í•  ìˆ˜ ì—†ë‹¤.\n",
    "    \n",
    "    return handler(request)\n",
    "\n",
    "uploaded_files_state = [\n",
    "    {\"name\": \"project_plan.pdf\", \"type\": \"pdf\", \"summary\": \"Q4 ë§ˆì¼ìŠ¤í†¤/ë°ë“œë¼ì¸ ìš”ì•½\"},\n",
    "    {\"name\": \"error_log.txt\", \"type\": \"text\", \"summary\": \"ìµœê·¼ ì—ëŸ¬ì™€ íƒ€ì„ìŠ¤íƒ¬í”„\"},\n",
    "]\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=[],\n",
    "    middleware=[inject_file_context],\n",
    "    state_schema=MyState\n",
    ")\n",
    "\n",
    "result = agent.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": \"ìµœê·¼ ë¡œê·¸ë¥¼ ì°¸ê³ í•´ì„œ ì„œë¹„ìŠ¤ ì¥ì•  ì›ì¸ ìš”ì•½í•´ì¤˜.\"}\n",
    "        ],\n",
    "        \"uploaded_files\": uploaded_files_state\n",
    "    },\n",
    ")\n",
    "\n",
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0d57340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì•ˆë…•í•˜ì„¸ìš”, ê³ ê° Aë‹˜.\n",
      "\n",
      "ìµœê·¼ ë°œìƒí•œ ì¥ì• ì— ëŒ€í•œ ì›ì¸ê³¼ ì¬ë°œ ë°©ì§€ ì¡°ì¹˜ë¥¼ ë§ì”€ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\n",
      "\n",
      "ì¥ì• ì˜ ì£¼ìš” ì›ì¸ì€ ì‹œìŠ¤í…œì˜ ë°ì´í„° ì²˜ë¦¬ ê³¼ì •ì—ì„œ ì˜ˆê¸°ì¹˜ ì•Šì€ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. ì´ ì˜¤ë¥˜ëŠ” íŠ¹ì • ì¡°ê±´ì—ì„œ ë°œìƒí•˜ëŠ” ë¬¸ì œë¡œ, ì¢…í•©ì ì¸ ë¶„ì„ì„ í†µí•´ í™•ì¸ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ì¬ë°œ ë°©ì§€ë¥¼ ìœ„í•´ ë‹¤ìŒê³¼ ê°™ì€ ì¡°ì¹˜ë¥¼ ì·¨í•  ì˜ˆì •ì…ë‹ˆë‹¤:\n",
      "1. ì˜¤ë¥˜ë¥¼ ìˆ˜ì •í•œ ì½”ë“œ ì—…ë°ì´íŠ¸: í•´ë‹¹ ì˜¤ë¥˜ë¥¼ ìˆ˜ì •í•œ íŒ¨ì¹˜ë¥¼ ê³§ ë°°í¬í•  ì˜ˆì •ì…ë‹ˆë‹¤.\n",
      "2. ëª¨ë‹ˆí„°ë§ ê°•í™”: ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§ì„ ê°•í™”í•˜ì—¬ ìœ ì‚¬í•œ ë¬¸ì œë¥¼ ì‚¬ì „ì— ë°œê²¬í•  ìˆ˜ ìˆë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.\n",
      "3. ì£¼ê¸°ì ì¸ ì ê²€: ì •ê¸°ì ìœ¼ë¡œ ì‹œìŠ¤í…œ ì ê²€ì„ ì‹¤ì‹œí•˜ì—¬ ì•ˆì •ì„±ì„ ë†’ì´ê² ìŠµë‹ˆë‹¤.\n",
      "\n",
      "ì¶”ê°€ì ì¸ ë¬¸ì˜ì‚¬í•­ì´ë‚˜ ë¶ˆí¸ì‚¬í•­ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“ ì§€ ë§ì”€í•´ ì£¼ì„¸ìš”.\n",
      "\n",
      "ê°ì‚¬í•©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# storeì™€ context ì‚¬ìš© ì˜ˆì‹œ ì½”ë“œ\n",
    "import os\n",
    "from dataclasses import dataclass\n",
    "from typing import Callable\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import wrap_model_call, ModelRequest, ModelResponse\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "@dataclass\n",
    "class Context:\n",
    "    user_id: str\n",
    "\n",
    "@wrap_model_call\n",
    "def inject_writing_style(\n",
    "    request: ModelRequest,\n",
    "    handler: Callable[[ModelRequest], ModelResponse]\n",
    ") -> ModelResponse:\n",
    "    \"\"\"Inject user's email writing style from Store.\"\"\"\n",
    "    user_id = request.runtime.context.user_id\n",
    "\n",
    "    store = request.runtime.store\n",
    "    writing_style = store.get((\"writing_style\",), user_id)\n",
    "\n",
    "    if writing_style:\n",
    "        style = writing_style.value\n",
    "        style_context = f\"\"\"Your writing style:\n",
    "        - Tone: {style.get('tone', 'professional')}\n",
    "        - Typical greeting: \"{style.get('greeting', 'Hi')}\"\n",
    "        - Typical sign-off: \"{style.get('sign_off', 'Best')}\"\n",
    "        - Example email you've written:\n",
    "        {style.get('example_email', '')}\"\"\"\n",
    "        messages = [\n",
    "            *request.messages,\n",
    "            {\"role\": \"user\", \"content\": style_context}\n",
    "        ]\n",
    "        request = request.override(messages=messages)\n",
    "\n",
    "    return handler(request)\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# ì¥ê¸° ë©”ëª¨ë¦¬ ì¤€ë¹„\n",
    "store = InMemoryStore()\n",
    "store.put((\"writing_style\",), \"u-001\", {\n",
    "    \"tone\": \"friendly and concise\",\n",
    "    \"greeting\": \"ì•ˆë…•í•˜ì„¸ìš”\",\n",
    "    \"sign_off\": \"ê°ì‚¬í•©ë‹ˆë‹¤\",\n",
    "    \"example_email\": \"ì•ˆë…•í•˜ì„¸ìš”, ì–´ì œ ìš”ì²­ì£¼ì‹  ë¡œê·¸ ë¶„ì„ ê²°ê³¼ë¥¼ ê³µìœ ë“œë¦½ë‹ˆë‹¤. í•µì‹¬ ì›ì¸ì€ ...\",\n",
    "})\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=[],\n",
    "    middleware=[inject_writing_style],\n",
    "    context_schema=Context,\n",
    "    store=store,\n",
    ")\n",
    "\n",
    "result = agent.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": \"ê³ ê° Aì—ê²Œ ì¥ì•  ì›ì¸ê³¼ ì¬ë°œ ë°©ì§€ ì¡°ì¹˜ì— ëŒ€í•œ ì´ë©”ì¼ ì´ˆì•ˆ ì‘ì„±í•´ì¤˜.\"}\n",
    "        ]\n",
    "    },\n",
    "    context=Context(user_id=\"u-001\")\n",
    ")\n",
    "\n",
    "print(result[\"messages\"][-1].content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e625973",
   "metadata": {},
   "source": [
    "#### Model Context ì¡°ì‘ ê¸°ë²• - Tools\n",
    "- íˆ´ì—ëŠ” ëª…í™•í•œ ì´ë¦„, ì„¤ëª…, ì¸ìˆ˜ ì´ë¦„, ì¸ìˆ˜ ì„¤ëª…ì´ í•„ìš”í•˜ë‹¤. \n",
    "    - ë‹¨ìˆœíˆ ë©”íƒ€ë°ì´í„°ê°€ ì•„ë‹ˆë¼ LLMì´ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•œ ëª¨ë¸ì˜ ì¶”ë¡ ì„ ì•ˆë‚´í•˜ëŠ” ì—­í• ì´ë‹¤.\n",
    "- íˆ´ì´ ë„ˆë¬´ ë§ìœ¼ë©´ ëª¨ë¸ì— ê³¼ë¶€í•˜(ì»¨í…ìŠ¤íŠ¸ ê³¼ë¶€í•˜)ë¥¼ ì¼ìœ¼ì¼œ ì˜¤ë¥˜ê°€ ì¦ê°€í•˜ê³ , ë„êµ¬ê°€ ë„ˆë¬´ ì ìœ¼ë©´ ê¸°ëŠ¥ì´ ì œí•œëœë‹¤.\n",
    "    - ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ì„¸íŠ¸ë¥¼ ì¡°ì •í•˜ê¸° ìœ„í•´ Model Context(state, store, context)ë¥¼ ì´ìš©í•œë‹¤.\n",
    "    - ì˜ˆ) ì¸ì¦ ì „ì—ëŠ” public toolë§Œ ë…¸ì¶œ, ì¸ì¦ í›„ì—ëŠ” private tool í™œì„±í™” ë“±\n",
    "- ì˜ˆì‹œ ì½”ë“œ\n",
    "    ```from langchain.tools import tool\n",
    "\n",
    "    @tool(parse_docstring=True)\n",
    "    def search_orders(\n",
    "        user_id: str,\n",
    "        status: str,\n",
    "        limit: int = 10\n",
    "    ) -> str:\n",
    "        \"\"\"Search for user orders by status.\n",
    "\n",
    "        Use this when the user asks about order history or wants to check\n",
    "        order status. Always filter by the provided status.\n",
    "\n",
    "        Args:\n",
    "            user_id: Unique identifier for the user\n",
    "            status: Order status: 'pending', 'shipped', or 'delivered'\n",
    "            limit: Maximum number of results to return\n",
    "        \"\"\"\n",
    "        # Implementation here\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4518a3bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "public_search í˜¸ì¶œ\n",
      "private_search í˜¸ì¶œ\n",
      "advanced_search í˜¸ì¶œ\n"
     ]
    }
   ],
   "source": [
    "# state ì‚¬ìš© ì˜ˆì‹œ ì½”ë“œ\n",
    "\n",
    "from langchain.agents import create_agent, AgentState\n",
    "from langchain.agents.middleware import wrap_model_call, ModelRequest, ModelResponse\n",
    "from typing import Callable\n",
    "from langchain.tools import tool\n",
    "from typing_extensions import TypedDict, NotRequired\n",
    "\n",
    "@tool(\"public_search\")\n",
    "def public_search():\n",
    "    \"\"\"\n",
    "    ì¸ì¦ ì—†ì´ ì¦‰ì‹œ ì‚¬ìš© ê°€ëŠ¥í•œ ê¸°ë³¸ ê²€ìƒ‰. ë¹ ë¥¸ ê°œìš”Â·ì¼ë°˜ ì •ë³´ê°€ ëª©í‘œì…ë‹ˆë‹¤.\n",
    "    \n",
    "    - ëª©ì : ë¡œê·¸ì¸ ì „/ì´ˆê¸° ë‹¨ê³„ì—ì„œ ê°€ë²¼ìš´ ì •ë³´ íƒìƒ‰ì„ ì‹ ì†íˆ ì œê³µí•©ë‹ˆë‹¤.\n",
    "    - ì „ì œì¡°ê±´: ì—†ìŒ(ë¹„ì¸ì¦ ì‚¬ìš©ì í¬í•¨).\n",
    "    - ì‚¬ìš© ì‹œì : ì§ˆë¬¸ì˜ ë²”ìœ„ê°€ ë„“ê±°ë‚˜, ë¯¼ê°/ì •ë°€ ì •ë³´ê°€ í•„ìš” ì—†ì„ ë•Œ.\n",
    "    - ì¶œë ¥: ìš”ì•½ ìˆ˜ì¤€ì˜ ê²°ê³¼(ê°œìš”/í‚¤ì›Œë“œ/ê°„ë‹¨ ì°¸ê³ ).\n",
    "    \"\"\"\n",
    "    print('public_search í˜¸ì¶œ')\n",
    "    return\n",
    "\n",
    "@tool(\"private_search\")\n",
    "def private_search():\n",
    "    \"\"\"\n",
    "    ì¸ì¦ ì‚¬ìš©ì ì „ìš©ì˜ ì •ë°€ ê²€ìƒ‰. ì‹ ë¢°ë„Â·ì •í™•ë„Â·ê·¼ê±° ì œì‹œë¥¼ ìš°ì„ í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    - ëª©ì : ê°œì¸í™”/ê¶Œí•œì´ í•„ìš”í•œ ì •ë°€ íƒìƒ‰(ì˜ˆ: ë‚´ë¶€ ì§€ì‹, ê³ ì‹ ë¢° ì¶œì²˜ êµì°¨ê²€ì¦).\n",
    "    - ì „ì œì¡°ê±´: authenticated=True (ë¯¸ë“¤ì›¨ì–´ì—ì„œ ë³´ì¥).\n",
    "    - ì‚¬ìš© ì‹œì : êµ¬ì²´ì  ê¸°ì¤€/ì œí•œì¡°ê±´/ì •í™•í•œ ê·¼ê±°ê°€ í•„ìš”í•œ ìš”ì²­ì¼ ë•Œ.\n",
    "    - ì¶œë ¥: ì¶œì²˜Â·ê·¼ê±°Â·í•„í„° ì¡°ê±´ì„ ë°˜ì˜í•œ ì •ë°€ ê²°ê³¼ ë° ë‹¤ìŒ ì•¡ì…˜ ì œì•ˆ.\n",
    "    \"\"\"\n",
    "    print('private_search í˜¸ì¶œ')\n",
    "    return\n",
    "\n",
    "@tool(\"advanced_search\")\n",
    "def advanced_search():\n",
    "    \"\"\"\n",
    "    ê³ ê¸‰ ì „ëµì„ í™œìš©í•œ ì‹¬ì¸µ ê²€ìƒ‰. ë©€í‹°ìŠ¤í…/êµì°¨ê²€ì¦/ì¬ê²€ìƒ‰ ë£¨í”„ë¡œ ì™„ì„±ë„ë¥¼ ë†’ì…ë‹ˆë‹¤.\n",
    "    \n",
    "    - ëª©ì : ë‚œë„ ë†’ì€ ì§ˆì˜ì— ëŒ€í•´ ë‹¨ê³„ì  ë¶„í•´, í›„ë³´êµ° ë¹„êµ, ì¬ì‹œë„Â·í™•ì¥ íƒìƒ‰ ìˆ˜í–‰.\n",
    "    - ì „ì œì¡°ê±´: authenticated=True ì´ë©´ì„œ ëŒ€í™”ê°€ ì¶©ë¶„íˆ ì§„í–‰ëœ ìƒíƒœ(ë¯¸ë“¤ì›¨ì–´ì—ì„œ ì¡°ê±´í™”).\n",
    "    - ì‚¬ìš© ì‹œì : ì„±ëŠ¥Â·ì •í™•ë„Â·ì¬í˜„ì„±ì„ ê·¹ëŒ€í™”í•´ì•¼ í•˜ê±°ë‚˜, ëŒ€ì•ˆ ë¹„êµ/ë­í‚¹ì´ í•„ìš”í•  ë•Œ.\n",
    "    - ì¶œë ¥: ë¹„êµí‘œÂ·ìŠ¤ì½”ì–´Â·ë¦¬ìŠ¤í¬/íŠ¸ë ˆì´ë“œì˜¤í”„ ë¶„ì„, ê¶Œì¥ì•ˆ ë° ê·¼ê±° ë¬¶ìŒ.\n",
    "    \"\"\"\n",
    "    print('advanced_search í˜¸ì¶œ')\n",
    "    return \n",
    "\n",
    "# state ìŠ¤í‚¤ë§ˆ ì •ì˜\n",
    "class Context(AgentState):\n",
    "    authenticated: NotRequired[bool]\n",
    "\n",
    "@wrap_model_call\n",
    "def state_based_tools(\n",
    "    request: ModelRequest,\n",
    "    handler: Callable[[ModelRequest], ModelResponse]\n",
    ") -> ModelResponse:\n",
    "    \"\"\"ëŒ€í™” ìƒíƒœë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ í•„í„° ë„êµ¬ì…ë‹ˆë‹¤.\"\"\"\n",
    "    # stateì—ì„œ ì‚¬ìš©ì ì¸ì¦ í™•ì¸\n",
    "    state = request.state\n",
    "    is_authenticated = state.get('authenticated', False)\n",
    "    message_count = len(state['messages'])\n",
    "\n",
    "    # ì¸ì¦ëœ ìƒíƒœì—ì„œë§Œ íŠ¹ì • íˆ´ ì ìš©\n",
    "    if not is_authenticated:\n",
    "        tools = [t for t in request.tools if t.name.startswith('public_')]\n",
    "        request = request.override(tools=tools) # request.toolsë¡œ ë®ì–´ ì“°ì§€ ëª»í•˜ê¸° ë•Œë¬¸ì— override() ì‚¬ìš© \n",
    "    elif message_count < 5: \n",
    "        # ëŒ€í™” ì´ˆê¸°ì—ëŠ” íˆ´ ì‚¬ìš© ì œí•œ\n",
    "        tools = [t for t in request.tools if t.name != \"advanced_search\"]\n",
    "        request = request.override(tools=tools)\n",
    "    \n",
    "    return handler(request)\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=[public_search, private_search, advanced_search],\n",
    "    middleware=[state_based_tools],\n",
    "    state_schema=Context\n",
    ")\n",
    "\n",
    "result = agent.invoke({\n",
    "    'messages': [{'role': 'user', 'content': 'ì¸ê³µì§€ëŠ¥ì— ëŒ€í•´ ì •ë°€ ë¶„ì„í•˜ê³  ê²€ìƒ‰í•´ì¤˜'}],\n",
    "    \"authenticated\": False\n",
    "})\n",
    "\n",
    "result2 = agent.invoke({\n",
    "    'messages': [{'role': 'user', 'content': 'ì¸ê³µì§€ëŠ¥ì— ëŒ€í•´ ì •ë°€ ë¶„ì„í•˜ê³  ê²€ìƒ‰í•´ì¤˜'}],\n",
    "    \"authenticated\": True\n",
    "})\n",
    "\n",
    "result3 = agent.invoke({\n",
    "    'messages': [{'role': 'user', 'content': 'ì¸ê³µì§€ëŠ¥ì— ëŒ€í•´ ê³ ê¸‰ ê²€ìƒ‰í•´ì¤˜'} for t in range(6)],\n",
    "    \"authenticated\": True\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2609cf87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Middleware] user user001 enabled tools: ['search_tool', 'analysis_tool', 'export_tool']\n",
      "analysis_tool í˜¸ì¶œ\n",
      "[Middleware] user user001 enabled tools: ['search_tool', 'analysis_tool', 'export_tool']\n",
      "ì¸ê³µì§€ëŠ¥ì— ëŒ€í•œ êµ¬ì²´ì ì¸ ë¶„ì„ì„ ì œê³µí•˜ê¸° ìœ„í•´ ëª‡ ê°€ì§€ ì£¼ìš” ì£¼ì œë¥¼ ë‹¤ë£° ìˆ˜ ìˆìŠµë‹ˆë‹¤:\n",
      "\n",
      "1. **ì •ì˜**: ì¸ê³µì§€ëŠ¥(AI)ì€ ì¸ê°„ì˜ ì¸ì§€ ê¸°ëŠ¥ì„ ëª¨ë°©í•˜ëŠ” ì»´í“¨í„° ì‹œìŠ¤í…œì´ë‚˜ ì†Œí”„íŠ¸ì›¨ì–´ì…ë‹ˆë‹¤. ì´ëŠ” í•™ìŠµ, ë¬¸ì œ í•´ê²°, ì–¸ì–´ ì´í•´ ë° ë¹„ì£¼ì–¼ ì¸ì‹ ë“± ë‹¤ì–‘í•œ ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "2. **ì—­ì‚¬**: AIì˜ ë°œì „ì€ 1950ë…„ëŒ€ì— ì‹œì‘ë˜ì–´, ì´ˆì°½ê¸°ì—ëŠ” ì£¼ë¡œ ê·œì¹™ ê¸°ë°˜ ì‹œìŠ¤í…œì— ì˜ì¡´í–ˆì§€ë§Œ, ì´í›„ ë¨¸ì‹ ëŸ¬ë‹ê³¼ ë”¥ëŸ¬ë‹ ê¸°ìˆ ì˜ ë°œì „ìœ¼ë¡œ ì¸í•´ ê²½ì´ë¡œìš´ ì§„ì „ì„ ì´ë£¨ì—ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "3. **ê¸°ìˆ **: ì¸ê³µì§€ëŠ¥ì˜ ì£¼ìš” ê¸°ìˆ ì—ëŠ” ë¨¸ì‹ ëŸ¬ë‹, ë”¥ëŸ¬ë‹, ìì—°ì–´ ì²˜ë¦¬(NLP), ì»´í“¨í„° ë¹„ì „ ë“±ì´ í¬í•¨ë©ë‹ˆë‹¤. ì´ë“¤ ê¸°ìˆ ì€ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  ì˜ˆì¸¡í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.\n",
      "\n",
      "4. **ì‘ìš© ë¶„ì•¼**: AIëŠ” ì˜ë£Œ, ê¸ˆìœµ, ì œì¡°, ììœ¨ì£¼í–‰ ìë™ì°¨, ìŠ¤ë§ˆíŠ¸ í™ˆ, ê³ ê° ì„œë¹„ìŠ¤ ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì— í™œìš©ë˜ê³  ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "5. **ìœ¤ë¦¬ì  ë¬¸ì œ**: AIì˜ ë°œì „ì— ë”°ë¼ ê°œì¸ì •ë³´ ë³´í˜¸, ì•Œê³ ë¦¬ì¦˜ì˜ í¸í–¥ì„±, ì¼ìë¦¬ ëŒ€ì²´ ë“± ë‹¤ì–‘í•œ ìœ¤ë¦¬ì  ë¬¸ì œê°€ ì œê¸°ë˜ê³  ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "6. **ë¯¸ë˜ ì „ë§**: AIëŠ” ì•ìœ¼ë¡œë„ ê³„ì† ë°œì „í•  ê²ƒì´ë©°, ì¸ê°„ ìƒí™œì˜ ì—¬ëŸ¬ ì¸¡ë©´ì„ ë³€í™”ì‹œí‚¬ ê²ƒìœ¼ë¡œ ê¸°ëŒ€ë˜ê³  ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ì¶”ê°€ì ìœ¼ë¡œ ê¶ê¸ˆí•œ ì ì´ë‚˜ êµ¬ì²´ì ìœ¼ë¡œ ì•Œê³  ì‹¶ì€ ë‚´ìš©ì´ ìˆë‹¤ë©´ ë§ì”€í•´ ì£¼ì„¸ìš”!\n"
     ]
    }
   ],
   "source": [
    "# storeì™€ context ì‚¬ìš© ì˜ˆì œ ì½”ë“œ\n",
    "from dataclasses import dataclass\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import wrap_model_call, ModelRequest, ModelResponse\n",
    "from typing import Callable\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "\n",
    "@dataclass\n",
    "class Context:\n",
    "    user_id: str\n",
    "\n",
    "@tool\n",
    "def search_tool():\n",
    "    \"\"\"ì¼ë°˜ ê²€ìƒ‰ íˆ´\"\"\"\n",
    "    print('search_tool í˜¸ì¶œ')\n",
    "    return \n",
    "\n",
    "@tool\n",
    "def analysis_tool():\n",
    "    \"\"\"ìì„¸í•œ ê²€ìƒ‰ ë° ë¶„ì„ íˆ´\"\"\"\n",
    "    print('analysis_tool í˜¸ì¶œ')\n",
    "    return\n",
    "\n",
    "@tool\n",
    "def export_tool():\n",
    "    \"\"\"ì „ë¬¸ê°€ìš© ê²€ìƒ‰ íˆ´\"\"\"\n",
    "    print('export_tool í˜¸ì¶œ')\n",
    "    return\n",
    "\n",
    "@wrap_model_call\n",
    "def store_based_tools(\n",
    "    request: ModelRequest,\n",
    "    handler: Callable[[ModelRequest], ModelResponse]\n",
    ") -> ModelResponse:\n",
    "    \"\"\"storeì˜ ì„ í˜¸ë„ì— ë”°ë¥¸ í•„í„°\"\"\"\n",
    "    user_id = request.runtime.context.user_id\n",
    "    store = request.runtime.store\n",
    "\n",
    "    feature_flags = store.get(('features',), user_id)\n",
    "\n",
    "    if feature_flags:\n",
    "        enabled_features = feature_flags.value.get('enabled_tools', [])\n",
    "        print(f\"[Middleware] user {user_id} enabled tools: {enabled_features}\")\n",
    "        tools = [t for t in request.tools if t.name in enabled_features]\n",
    "        request = request.override(tools=tools)\n",
    "    \n",
    "    return handler(request)\n",
    "\n",
    "# ì„ì‹œë¡œ ì„ í˜¸ íˆ´ ë©”ëª¨ë¦¬ ë„£ì–´ì¤Œ\n",
    "store=InMemoryStore()\n",
    "store.put(('features',), 'user001', {\n",
    "    'enabled_tools': ['search_tool', 'analysis_tool', 'export_tool']\n",
    "})\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=[search_tool, analysis_tool, export_tool],\n",
    "    middleware=[store_based_tools],\n",
    "    context_schema=Context,\n",
    "    store=store\n",
    ")\n",
    "\n",
    "result = agent.invoke({\n",
    "    'messages': [{'role': 'user', 'content': 'ì¸ê³µì§€ëŠ¥ì— ëŒ€í•´ ë¶„ì„í•´ì¤˜'}]\n",
    "    },\n",
    "    context=Context(user_id='user001')\n",
    ")\n",
    "\n",
    "print(result.get('messages')[-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fa7585",
   "metadata": {},
   "source": [
    "#### Model Context - model\n",
    "- ëª¨ë¸ë§ˆë‹¤ ê°•ì , ë¹„ìš©, ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš°ê°€ ë‹¤ë¥´ë‹¤.\n",
    "- ì—ì´ì „íŠ¸ ì‹¤í–‰ ì¤‘ì— taskì— ë§ëŠ” ëª¨ë¸ì„ ì„ ì •í•  ë•Œ ì‚¬ìš© ê°€ëŠ¥í•˜ë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "632cb564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í˜„ì¬ ëª¨ë¸: gpt-4o-mini\n",
      "í˜„ì¬ ëª¨ë¸: gpt-5\n",
      "í˜„ì¬ ëª¨ë¸: gpt-4o\n"
     ]
    }
   ],
   "source": [
    "# state ì‚¬ìš© ì˜ˆì œ ì½”ë“œ\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import wrap_model_call, ModelRequest, ModelResponse\n",
    "from langchain.chat_models import init_chat_model\n",
    "from typing import Callable\n",
    "\n",
    "large_model = init_chat_model(\"gpt-5\")\n",
    "standard_model = init_chat_model(\"gpt-4o\")\n",
    "efficient_model = init_chat_model(\"gpt-4o-mini\")\n",
    "\n",
    "@wrap_model_call\n",
    "def state_based_model(\n",
    "    request: ModelRequest,\n",
    "    handler: Callable[[ModelRequest], ModelResponse]\n",
    ") -> ModelResponse:\n",
    "    \"\"\"ëŒ€í™”ì˜ ê¸¸ì´ì— ë”°ë¼ ì ì ˆí•œ ëª¨ë¸ ì„ íƒ\"\"\"\n",
    "    message_count = len(request.state[\"messages\"])\n",
    "\n",
    "    if message_count > 20:\n",
    "        model = large_model\n",
    "    elif message_count > 10:\n",
    "        model = standard_model\n",
    "    else:\n",
    "        model = efficient_model\n",
    "\n",
    "    request = request.override(model=model)\n",
    "    print('í˜„ì¬ ëª¨ë¸:', request.model.model_name)\n",
    "\n",
    "    return handler(request)\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=[],\n",
    "    middleware=[state_based_model]\n",
    ")\n",
    "\n",
    "result = agent.invoke({'messages': [{'role': 'user', 'content': 'ì¸ê³µì§€ëŠ¥ì— ëŒ€í•´ì„œ ì•Œë ¤ì¤˜'}]})\n",
    "result2 = agent.invoke({'messages': [{'role': 'user', 'content': 'ì¸ê³µì§€ëŠ¥ì— ëŒ€í•´ì„œ ì•Œë ¤ì¤˜'} for t in range(21)]})\n",
    "result3 = agent.invoke({'messages': [{'role': 'user', 'content': 'ì¸ê³µì§€ëŠ¥ì— ëŒ€í•´ì„œ ì•Œë ¤ì¤˜'} for t in range(11)]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a2421a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í˜„ì¬ ëª¨ë¸: gpt-4o\n"
     ]
    }
   ],
   "source": [
    "# contextì™€ store ì‚¬ìš© ì˜ˆì œ ì½”ë“œ\n",
    "from dataclasses import dataclass\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import wrap_model_call, ModelRequest, ModelResponse\n",
    "from langchain.chat_models import init_chat_model\n",
    "from typing import Callable\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "\n",
    "@dataclass\n",
    "class Context:\n",
    "    user_id: str\n",
    "\n",
    "MODEL_MAP = {\n",
    "    \"gpt-4o\": init_chat_model(\"gpt-4o\"),\n",
    "    \"gpt-4o-mini\": init_chat_model(\"gpt-4o-mini\"),\n",
    "    \"gpt-5\": init_chat_model(\"gpt-5\"),\n",
    "}\n",
    "\n",
    "@wrap_model_call\n",
    "def store_based_model(\n",
    "    request: ModelRequest,\n",
    "    handler: Callable[[ModelRequest], ModelResponse]\n",
    ") -> ModelResponse:\n",
    "    \"\"\"ì €ì¥ì†Œì— ì €ì¥ëœ ì„ í˜¸ë„ ê¸°ë°˜ìœ¼ë¡œ ëª¨ë¸ ì„ íƒ\"\"\"\n",
    "    user_id = request.runtime.context.user_id\n",
    "    store = request.runtime.store\n",
    "    user_prefs = store.get(('preferences',), user_id)\n",
    "\n",
    "    if user_prefs:\n",
    "        preferred_model = user_prefs.value.get('preferred_model')\n",
    "        if preferred_model and preferred_model in MODEL_MAP:\n",
    "            request = request.override(model=MODEL_MAP[preferred_model])\n",
    "\n",
    "    print('í˜„ì¬ ëª¨ë¸:', request.model.model_name)\n",
    "    return handler(request) \n",
    "    \n",
    "# ì„ì‹œ ë©”ëª¨ë¦¬ ì €ì¥\n",
    "store = InMemoryStore()\n",
    "store.put(('preferences',), 'user001', {'preferred_model': 'gpt-4o'})\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=[],\n",
    "    middleware=[store_based_model],\n",
    "    context_schema=Context,\n",
    "    store=store\n",
    ")\n",
    "\n",
    "result = agent.invoke({\n",
    "        'messages': [{'role': 'user', 'content': 'ì¸ê³µì§€ëŠ¥ì— ëŒ€í•´ì„œ ì•Œë ¤ì¤˜'}]\n",
    "    }, \n",
    "    context=Context(user_id='user001')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83b8ebf",
   "metadata": {},
   "source": [
    "#### Model Context - write\n",
    "- ë„êµ¬ëŠ” ê²°ê³¼ë¥¼ ëª¨ë¸ì— ì§ì ‘ ë°˜í™˜í•  ë¿ë§Œ ì•„ë‹ˆë¼ ì—ì´ì „íŠ¸ì˜ ë©”ëª¨ë¦¬ë¥¼ ì—…ë°ì´íŠ¸í•  ìˆ˜ ìˆë‹¤.\n",
    "    - í–¥í›„ ë‹¨ê³„ì—ì„œ ì¤‘ìš”í•œ ë§¥ë½ì„ í™œìš©í•  ìˆ˜ ìˆë„ë¡ í•œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "10c91989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[correct] : ì¸ì¦ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?\n",
      "[wrong] : ë¹„ë°€ë²ˆí˜¸ê°€ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.\n"
     ]
    }
   ],
   "source": [
    "# state ì‚¬ìš© ì˜ˆì œ ì½”ë“œ\n",
    "from langchain.tools import tool, ToolRuntime\n",
    "from langchain.agents import create_agent\n",
    "from langgraph.types import Command\n",
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "@tool\n",
    "def authenticate_user(\n",
    "    password: str,\n",
    "    runtime: ToolRuntime\n",
    ") -> Command:\n",
    "    \"\"\"\n",
    "    Authenticate user and update State.\n",
    "    \"\"\"\n",
    "    if password == 'correct':\n",
    "        return Command(\n",
    "            update={\n",
    "                \"authenticated\": True,\n",
    "                \"messages\": [ToolMessage(\n",
    "                    content=\"Authentication successful\",\n",
    "                    tool_call_id=runtime.tool_call_id\n",
    "                )]\n",
    "            }\n",
    "        )\n",
    "    else:\n",
    "        return Command(\n",
    "            update={\n",
    "                \"authenticated\": False,\n",
    "                \"messages\": [ToolMessage(\n",
    "                    content=\"Authentication failed\",\n",
    "                    tool_call_id=runtime.tool_call_id\n",
    "                )]\n",
    "            }\n",
    "        )\n",
    "    \n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=[authenticate_user]\n",
    ")\n",
    "\n",
    "result = agent.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"ë¹„ë°€ë²ˆí˜¸ëŠ” correctì…ë‹ˆë‹¤\"}]\n",
    "})\n",
    "\n",
    "print('[correct] :',result.get('messages')[-1].content)\n",
    "\n",
    "result2 = agent.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"ë¹„ë°€ë²ˆí˜¸ëŠ” wrongì…ë‹ˆë‹¤\"}]\n",
    "})\n",
    "\n",
    "print('[wrong] :', result2.get('messages')[-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fd668579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your theme preference has been saved as \"dark.\"\n",
      "{'theme': 'dark'}\n"
     ]
    }
   ],
   "source": [
    "# contextì™€ store ì‚¬ìš© ì˜ˆì œ ì½”ë“œ\n",
    "from dataclasses import dataclass\n",
    "from langchain.tools import tool, ToolRuntime\n",
    "from langchain.agents import create_agent\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "\n",
    "@dataclass\n",
    "class Context:\n",
    "    user_id: str\n",
    "\n",
    "@tool\n",
    "def save_preference(\n",
    "    preference_key: str,\n",
    "    preference_value: str,\n",
    "    runtime: ToolRuntime[Context]\n",
    ") -> str:\n",
    "    \"\"\"Save user preference to Store.\"\"\"\n",
    "    user_id = runtime.context.user_id\n",
    "\n",
    "    # Read existing preferences\n",
    "    store = runtime.store\n",
    "    existing_prefs = store.get((\"preferences\",), user_id)\n",
    "\n",
    "    # Merge with new preference\n",
    "    prefs = existing_prefs.value if existing_prefs else {}\n",
    "    prefs[preference_key] = preference_value\n",
    "\n",
    "    # Write to Store: save updated preferences\n",
    "    store.put((\"preferences\",), user_id, prefs)\n",
    "\n",
    "    return f\"Saved preference: {preference_key} = {preference_value}\"\n",
    "\n",
    "store = InMemoryStore()\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"gpt-4o\",\n",
    "    tools=[save_preference],\n",
    "    context_schema=Context,\n",
    "    store=store\n",
    ")\n",
    "\n",
    "# ì—ì´ì „íŠ¸ ì‹¤í–‰\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Save my theme preference as dark\"}]},\n",
    "    context=Context(user_id=\"user_123\")\n",
    ")\n",
    "\n",
    "print(result.get('messages')[-1].content)\n",
    "print(store.get(('preferences',), 'user_123').value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
