{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "642b13b7",
   "metadata": {},
   "source": [
    "### 목적\n",
    "- 실시간 업데이트 표면화를 위해 스트리밍 구현하여 UX를 향상 -> LLM의 지연 시간을 처리할 때 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fa08b4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain.agents import create_agent\n",
    "from langchain.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.config import get_stream_writer  \n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464526fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"\n",
    "    주어진 도시의 현재 날씨를 반환합니다.\n",
    "    \"\"\"\n",
    "    return f'{city}는 항상 맑음입니다.'\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model='gpt-4o-mini',\n",
    "    api_key=os.getenv('OPENAI_API_KEY')\n",
    ")\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=[get_weather],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd9df4e",
   "metadata": {},
   "source": [
    "#### 1. updates\n",
    "- 각 스텝(노드 실행) 후 상태 변화를 필터링 \n",
    "- 도구 호출 -> 응답 -> 최종 응답같은 에이전트 진행 상황을 단계별로 확인 가능\n",
    "- 사용처: 현재 무슨 단계인지 UI에 로그/타임라인 출력할 때\n",
    "- 전체 상태가 아니라 변경점만 오므로 누적 관리 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "042278cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: model\n",
      "content: [{'type': 'tool_call', 'name': 'get_weather', 'args': {'city': '서울'}, 'id': 'call_Ojf8Mch6XIYXFfhxb9v4na1J'}]\n",
      "step: tools\n",
      "content: [{'type': 'text', 'text': '서울는 항상 맑음입니다.'}]\n",
      "step: model\n",
      "content: [{'type': 'text', 'text': '현재 서울의 날씨는 항상 맑습니다.'}]\n"
     ]
    }
   ],
   "source": [
    "for chunk in agent.stream(\n",
    "    {'messages': [{'role': 'user', 'content': '서울의 날씨는 어때?'}]},\n",
    "    stream_mode='updates'\n",
    "):\n",
    "    for step, data in chunk.items():\n",
    "        print(f'step: {step}')\n",
    "        print(f'content: {data[\"messages\"][-1].content_blocks}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ead69f8",
   "metadata": {},
   "source": [
    "#### 2. messages\n",
    "- LLM의 토큰/메시지 청크 + 메타데이터\n",
    "- 사용처: 토큰 단위 출력(타이핑 효과), 특정 노드별 토큰만 필터링할 때\n",
    "- UX는 향상되지만 상태 변화는 직접 계산해야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5d7c9a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node: model\n",
      "content: [{'type': 'tool_call_chunk', 'id': 'call_5sRubjtaqaJAH6AzbLnqmxR9', 'name': 'get_weather', 'args': '', 'index': 0}]\n",
      "\n",
      "\n",
      "node: model\n",
      "content: [{'type': 'tool_call_chunk', 'id': None, 'name': None, 'args': '{\"', 'index': 0}]\n",
      "\n",
      "\n",
      "node: model\n",
      "content: [{'type': 'tool_call_chunk', 'id': None, 'name': None, 'args': 'city', 'index': 0}]\n",
      "\n",
      "\n",
      "node: model\n",
      "content: [{'type': 'tool_call_chunk', 'id': None, 'name': None, 'args': '\":\"', 'index': 0}]\n",
      "\n",
      "\n",
      "node: model\n",
      "content: [{'type': 'tool_call_chunk', 'id': None, 'name': None, 'args': '서울', 'index': 0}]\n",
      "\n",
      "\n",
      "node: model\n",
      "content: [{'type': 'tool_call_chunk', 'id': None, 'name': None, 'args': '\"}', 'index': 0}]\n",
      "\n",
      "\n",
      "node: model\n",
      "content: []\n",
      "\n",
      "\n",
      "node: model\n",
      "content: []\n",
      "\n",
      "\n",
      "node: model\n",
      "content: []\n",
      "\n",
      "\n",
      "node: tools\n",
      "content: [{'type': 'text', 'text': '서울는 항상 맑음입니다.'}]\n",
      "\n",
      "\n",
      "node: model\n",
      "content: []\n",
      "\n",
      "\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '서울'}]\n",
      "\n",
      "\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '의'}]\n",
      "\n",
      "\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' 날'}]\n",
      "\n",
      "\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '씨'}]\n",
      "\n",
      "\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '는'}]\n",
      "\n",
      "\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' 항상'}]\n",
      "\n",
      "\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' 맑'}]\n",
      "\n",
      "\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '습니다'}]\n",
      "\n",
      "\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '.'}]\n",
      "\n",
      "\n",
      "node: model\n",
      "content: []\n",
      "\n",
      "\n",
      "node: model\n",
      "content: []\n",
      "\n",
      "\n",
      "node: model\n",
      "content: []\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for token, metadata in agent.stream(\n",
    "    {'messages': [{'role': 'user', 'content': '서울의 날씨는 어때?'}]},\n",
    "    stream_mode='messages'\n",
    "):\n",
    "    print(f'node: {metadata[\"langgraph_node\"]}')\n",
    "    print(f'content: {token.content_blocks}')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e87a28b",
   "metadata": {},
   "source": [
    "#### 3. custom\n",
    "- 노드/툴 내부에서 임의로 get_stream_writer()로 사용자 정의 이벤트를 출력\n",
    "- 사용처: LLM외 임의 내용(진행률, 중간 산출물 등) 또는 LangChain이 아닌 LLM 클라이언트 토큰을 흘릴 때\n",
    "- 유연하지만 직접 이벤트를 작성하고 파싱 규칙을 스스로 정해야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec116886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "도시에 대한 데이터 조회: 서울\n",
      "도시에 대한 데이터 획득: 서울\n"
     ]
    }
   ],
   "source": [
    "# custom 모드 확인용 툴\n",
    "## 내부에서 사용자 정의 이벤트를 사용하여 임의의 내용을 출력한다.\n",
    "@tool\n",
    "def get_weather2(city: str) -> str:\n",
    "    \"\"\"\n",
    "    주어진 도시의 현재 날씨를 반환합니다.\n",
    "    \"\"\"\n",
    "    writer = get_stream_writer()\n",
    "    writer(f'도시에 대한 데이터 조회: {city}')\n",
    "    writer(f'도시에 대한 데이터 획득: {city}')\n",
    "    return f'{city}는 항상 맑음입니다.'\n",
    "\n",
    "# custom 모드 확인용 에이전트\n",
    "custom_agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=[get_weather2],\n",
    ")\n",
    "\n",
    "for chunk in custom_agent.stream(\n",
    "    {'messages': [{'role': 'user', 'content': '서울의 날씨는 어때?'}]},\n",
    "    stream_mode='custom'\n",
    "):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88af6911",
   "metadata": {},
   "source": [
    "#### 이외 stream_mode 종류\n",
    "- values: 각 스텝(노드) 실행 직후의 \"전체 상태 스냅샷\"이 출력 -> updates는 변경 부분, values는 전체 상태\n",
    "- debug: 실행 전반의 디버그/트레이스 이벤트 출력 -> 개발 단계에서 추적할 때만 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a459c5b",
   "metadata": {},
   "source": [
    "#### mode 여러 개 사용\n",
    "- stream_mode는 리스트 형태로 ['messages', 'updates', ...]로 지정할 수도 있다.\n",
    "- 이 때 순서는 중요하지 않다. \n",
    "- 지정한 모든 이벤트를 감시하느라 부하가 증가할 수 있음\n",
    "- mode별로 다른 데이터 구조가 들어오므로, 구분해서 처리해야 한다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
