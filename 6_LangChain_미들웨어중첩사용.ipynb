{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fdb2636",
   "metadata": {},
   "source": [
    "### 목적\n",
    "- LangChain 미들웨어를 중첩으로 사용하여 적용 순서 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71188cef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain.agents import create_agent\n",
    "from langchain.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents.middleware import wrap_model_call, wrap_tool_call\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b60db31",
   "metadata": {},
   "source": [
    "#### middleware에 같은 종류의 데코레이터를 여러 개 사용할 수 있을까?\n",
    "- 답: \n",
    "    - 같은 종류의 데코레이터를 여러 개 사용할 수 있다.\n",
    "    - 실행 순서는 middleware 리스트의 앞에서 뒤로 감싸지고, 호출 후에는 반대 방향으로 풀린다.\n",
    "- 예시) \n",
    "    - middleward = [mw1, mw2, tw1, tw2]\n",
    "    1. mw1(before) -> 모델 호출 전에 가드레일 체크\n",
    "    2. mw2(before) -> 프롬프트에 타임스탬프 추가\n",
    "    3. LLM호출 -> LLM이 \"get_weather 툴 써야겠다\" 결정\n",
    "    4. tw1(before) -> 툴 입력이 빈 값이면 \"서울\"로 보정\n",
    "    5. tw2(before) -> 툴 호출 로깅 시작\n",
    "    6. 툴 실행(get_weather)\n",
    "    7. tw2(after) -> 툴 결과 로깅 종료\n",
    "    8. tw1(after) -> 툴 결과가 None이면 \"데이터 없음\"으로 대체\n",
    "    9. LLM 재호출 -> Observation 반영하여 최종 답 생성\n",
    "    10. mw2(after) -> 응답 톤을 \"간결\"로 정리\n",
    "    11. mw1(after) -> 금지 정보가 없는지 검사\n",
    "    12. 최종 응답 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd429dfe",
   "metadata": {},
   "source": [
    "#### middleware=[mw1, mw2, tw1, tw2] 라면\n",
    "- 모델 단계: mw1(before) -> mw2(before) -> (LLM) -> mw2(after) -> mw1(after)\n",
    "- 툴 단계:   tw1(before) -> tw2(before) -> (TOOL) -> tw2(after) -> tw1(after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2295f00d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mw1(before)\n",
      "mw2(before)\n",
      "mw2(after)\n",
      "mw1(after)\n",
      "tw1(before)\n",
      "tw2(before)\n",
      "[TOOL 실행 중: get_weather]\n",
      "tw2(after)\n",
      "tw1(after)\n",
      "mw1(before)\n",
      "mw2(before)\n",
      "mw2(after)\n",
      "mw1(after)\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model='gpt-4o-mini',\n",
    "    api_key=os.getenv('OPENAI_API_KEY')\n",
    ")\n",
    "\n",
    "@tool\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"주어진 도시의 현재 날씨를 반환합니다.\"\"\"\n",
    "    print(\"[TOOL 실행 중: get_weather]\")\n",
    "    return f\"오늘 {city}의 날씨는 맑음입니다.\"\n",
    "\n",
    "@wrap_model_call\n",
    "def mw1(req, call_next):\n",
    "    print(\"mw1(before)\")\n",
    "    out = call_next(req)\n",
    "    print(\"mw1(after)\")\n",
    "    return out\n",
    "\n",
    "@wrap_model_call\n",
    "def mw2(req, call_next):\n",
    "    print(\"mw2(before)\")\n",
    "    out = call_next(req)\n",
    "    print(\"mw2(after)\")\n",
    "    return out\n",
    "\n",
    "@wrap_tool_call\n",
    "def tw1(call, call_next):\n",
    "    print(\"tw1(before)\")\n",
    "    out = call_next(call)\n",
    "    print(\"tw1(after)\")\n",
    "    return out\n",
    "\n",
    "@wrap_tool_call\n",
    "def tw2(call, call_next):\n",
    "    print(\"tw2(before)\")\n",
    "    out = call_next(call)\n",
    "    print(\"tw2(after)\")\n",
    "    return out\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=[get_weather],\n",
    "    middleware=[mw1, mw2, tw1, tw2]\n",
    ")\n",
    "\n",
    "result = agent.invoke({'messages': [{'role':'user', 'content': '부산 날씨 어때?'}]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca2e1f4",
   "metadata": {},
   "source": [
    "#### 1. 모델 호출 (플래닝 단계)\n",
    "- mw1(before) → mw2(before) → (LLM) → mw2(after) → mw1(after)\n",
    "#### 2. 툴 호출\n",
    "- tw1(before) → tw2(before) → (TOOL) → tw2(after) → tw1(after)\n",
    "#### 3. 모델 호출 (최종 답 생성 단계)\n",
    "- mw1(before) → mw2(before) → (LLM) → mw2(after) → mw1(after)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7929ca16",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
