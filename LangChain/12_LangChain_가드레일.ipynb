{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5999a533",
   "metadata": {},
   "source": [
    "### 목적\n",
    "- 에이전트 실행의 핵심 지점에서 안전, 일관성을 보장하기 위해 Guardrail 적용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8f8264",
   "metadata": {},
   "source": [
    "#### 가드레일의 두 가지 접근: 결정적(Deterministic) vs 모델 기반(Model-based)\n",
    "\n",
    "\n",
    "| 구분                                                                        | 개념                | 장점               | 단점              | 예시                   |\n",
    "| ------------------------------------------------------------------------- | ----------------- | ---------------- | --------------- | -------------------- |\n",
    "| **결정적**                                                                   | 규칙/정규식/키워드/명시적 체크 | 빠르고 예측 가능, 비용↓   | 미묘한 케이스 놓칠 수 있음 | 금지어·패턴 필터, 범위·길이 제약  |\n",
    "| **모델 기반**                                                                 | LLM/분류기로 의미론적 평가  | 미묘한 위반 포착, 맥락 인지 | 느리고 비용↑         | 응답 안전성 LLM 평가, 품질 평가 |\n",
    "\n",
    "- 결정적 방식은 입력 텍스트의 의미를 이해하지 않고 오로지 패턴(정규식/내장 detector)만 본다.\n",
    "- 두 접근을 모두 사용하여 레이어링(겹겹이 쌓기)를 권장한다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67621490",
   "metadata": {},
   "source": [
    "#### PII 감지\n",
    "- 개인 식별 정보(PII)를 감지하고 처리하기 위한 내장 미들웨어 제공\n",
    "\n",
    "| Strategy | 설명 | 예시 | \n",
    "|-----------|--------------|----------|\n",
    "| `redact` | 특정 정보를 `[REDACTED_TYPE]` 형태로 완전히 대체 | `[REDACTED_EMAIL]` |\n",
    "| `mask` | 일부만 가려서 표시 (예: 마지막 4자리 노출) | `****-****-****-1234` |\n",
    "| `hash` | 동일한 입력값이면 항상 같은 해시값으로 대체 | `a8f5f167...` |\n",
    "| `block` | 해당 정보가 감지되면 예외를 발생시킴 | Error thrown |\n",
    "\n",
    "- apply_to_input=True -> before_model (모델 입력 전)\n",
    "- apply_to_output=True -> after_model (모델 응답 후)\n",
    "- apply_to_tool_results=True -> after_tool (툴 실행 결과 후)\n",
    "- before_tool은 내장 옵션이 없어서 @wrap_tool_call로 직접 커스텀 구현 필요\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c6357b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='My email is [REDACTED_EMAIL] and card is ****-****-****-9010', additional_kwargs={}, response_metadata={}, id='1dbb4bf3-ed05-4606-96f1-b1f1456ce709'), AIMessage(content=\"I'm sorry, but I can't assist with that information. If you have a specific inquiry or need help with customer service or emails, please let me know how I can assist you within those areas.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 40, 'prompt_tokens': 74, 'total_tokens': 114, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_65564d8ba5', 'id': 'chatcmpl-CYjLiR9O6B3NH41VjASBy3cGlzlHh', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--cf048911-6bda-4388-86e3-a14ad224c08f-0', usage_metadata={'input_tokens': 74, 'output_tokens': 40, 'total_tokens': 114, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.tools import tool\n",
    "from langchain.agents.middleware import PIIMiddleware\n",
    "\n",
    "@tool\n",
    "def customer_service_tool():\n",
    "    \"\"\"고객 서비스 제공 툴\"\"\"\n",
    "    return\n",
    "\n",
    "@tool\n",
    "def email_tool():\n",
    "    \"\"\"이메일 제공 툴\"\"\"\n",
    "    return\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"gpt-4o\",\n",
    "    tools=[customer_service_tool, email_tool],\n",
    "    middleware=[\n",
    "        # Redact emails in user input before sending to model\n",
    "        PIIMiddleware(\n",
    "            \"email\",\n",
    "            strategy=\"redact\",\n",
    "            apply_to_input=True, # 모델 호출 전에 입력을 처리 -> before_model 단계\n",
    "        ),\n",
    "        # Mask credit cards in user input\n",
    "        PIIMiddleware(\n",
    "            \"credit_card\",\n",
    "            detector=r\"\\b(?:\\d[ -]*?){13,19}\\b\",\n",
    "            strategy=\"mask\",\n",
    "            apply_to_input=True,\n",
    "        ),\n",
    "        # Block API keys - raise error if detected\n",
    "        PIIMiddleware(\n",
    "            \"api_key\",\n",
    "            detector=r\"sk-[a-zA-Z0-9]{32}\",\n",
    "            strategy=\"block\",\n",
    "            apply_to_input=True,\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "\n",
    "# When user provides PII, it will be handled according to the strategy\n",
    "result = agent.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"My email is john.doe@example.com and card is 4532-1234-5678-9010\"}]\n",
    "})\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da029cd",
   "metadata": {},
   "source": [
    "#### Human-in-the-loop\n",
    "- 민감한 작업을 실행하기 전에 사람의 승인을 요구하는 내장 미들웨어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0df043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이메일 전송 툴 선택\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.tools import tool\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import HumanInTheLoopMiddleware\n",
    "from langchain.agents.middleware import wrap_model_call, wrap_tool_call\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "# InMemorySaver: LangGraph에서 제공하는 체크포인터 \n",
    "## -> 에이전트의 상태(state)나 대화 히스토리를 메모리(RAM)에 임시로 저장하는 클래스\n",
    "from langgraph.types import Command\n",
    "# Command: 그래프 실행을 제어할 때 쓰는 지시 객체 \n",
    "## -> 노드가 반환값으로 Command를 넘기면 LangGraph는 그 지시에 따라 \n",
    "## 실행을 재개(resume)하거나 다음 노드로 라우팅하고 상태(state)를 업데이트한다.\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "@tool('search') # 툴의 이름과 미들웨어의 interrupt_on에 적은 키가 같아야 멈춘다.\n",
    "def search_tool():\n",
    "    \"\"\"검색 툴\"\"\"\n",
    "    print('검색 툴 선택')\n",
    "    return\n",
    "\n",
    "@tool('send_email')\n",
    "def send_email_tool():\n",
    "    \"\"\"이메일 전송 툴\"\"\"\n",
    "    print('이메일 전송 툴 선택')\n",
    "    return\n",
    "\n",
    "@tool('delete_database')\n",
    "def delete_database_tool():\n",
    "    \"\"\"DB 데이터 삭제 툴\"\"\"\n",
    "    print('DB 데이터 삭제 툴 선택')\n",
    "    return\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-4o-mini', api_key=os.getenv('OPENAI_API_KEY'))\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=[search_tool, send_email_tool, delete_database_tool],\n",
    "    middleware=[\n",
    "        HumanInTheLoopMiddleware(\n",
    "            interrupt_on={\n",
    "                # send_email과 delete_database는 승인 필요(True)\n",
    "                \"send_email\": True,\n",
    "                \"delete_database\": True,\n",
    "                # search는 자동 허용(False)\n",
    "                \"search\": False,\n",
    "            }\n",
    "        ),\n",
    "    ],\n",
    "    # 중단 시점의 에이전트 상태를 저장 -> 필수\n",
    "    checkpointer=InMemorySaver(),\n",
    ")\n",
    "\n",
    "# 스레드(대화) 식별자 지정 -> thread_id 키로 중단 시점의 상태를 저장/조회한다.\n",
    "# 중단한 대화를 똑같은 ID로 다시 불러와서 이어가야 하므로 반드시 필요 -> 보통 세션ID나 채팅ID로 유니크한 값 지정\n",
    "config = {\"configurable\": {\"thread_id\": \"some_id\"}}\n",
    "\n",
    "# 이메일 전송 요청 \n",
    "result = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"팀에 메일 전송해줘\"}]},\n",
    "    config=config\n",
    ")\n",
    "## -> 에이전트가 send_email_tool을 선택하려고 시도함\n",
    "## -> HumanInTheLoopMiddleware 설정에서 {\"send_email\": True} 로 승인 필요하다고 지정되어 있음\n",
    "## -> 툴 실행 직전에 멈춤(interrupt)\n",
    "## -> LangGraph가 중단 상태(checkpoint)를 메모리에 저장 \n",
    "## -> 아직 LLM 실행 안 됨(툴 실행하지 못한 상태)\n",
    "\n",
    "# 사용자가 의견에 따라 아래 실행\n",
    "\n",
    "# 실행 재개(resume)\n",
    "result = agent.invoke(\n",
    "    Command(resume={\"decisions\": [{\"type\": \"approve\"}]}), \n",
    "    ## Command 객체를 넘겨 실행 제어\n",
    "    ## resume은 재개 하라는 뜻\n",
    "    ## 'type': 'approve'는 승인한다는 뜻\n",
    "    config=config  \n",
    "    ## 동일한 스레드를 불러서 대화 재개\n",
    ")\n",
    "## -> 여기서 툴 실행"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516b252f",
   "metadata": {},
   "source": [
    "#### 커스텀 가드레일\n",
    "- 정교한 가드레일을 위해 사용자 지정 미들웨어를 만든다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2f1612",
   "metadata": {},
   "source": [
    "##### Before agent guardrails\n",
    "- \"before agent\" 훅을 사용하여 각 호출 시작 시 요청을 한 번 검증한다.\n",
    "- 인증, 속도 제한, 부적절한 요청 차단과 같은 세션 수준 검사를 처리 시작 전에 수행하는 데 유용하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "80f6135b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "부적절한 내용이 포함된 요청은 처리할 수 없습니다. 요청 내용을 다시 작성해 주세요.\n"
     ]
    }
   ],
   "source": [
    "from typing import Any\n",
    "# Any: 타입 힌트에서 아무 타입이나 들어올 수 있음을 뜻하는 타입 -> 예) list[Any], dict[str, Any] 등\n",
    "from langchain.agents.middleware import AgentMiddleware, AgentState, hook_config\n",
    "# hook_config: 미들웨어 훅에 메타설정을 부여하는 데코레이터\n",
    "## 점프 허용 노드 지정 -> 훅 내부에서 흐름 제어\n",
    "from langgraph.runtime import Runtime\n",
    "# Runtime: 훅 인자로 전달되는 그래프 실행기(런타임) 핸들의 타입\n",
    "## 에이전트/그래프 실행 중 컨텍스트와 흐름을 제어하는 도구\n",
    "## 가드레일에서 차단, 우회, 대체응답을 구현할 때나 동적 라우팅 등에 사용\n",
    "\n",
    "@tool('search')\n",
    "def search_tool():\n",
    "    \"\"\"검색 툴\"\"\"\n",
    "    return\n",
    "\n",
    "class ContentFilterMiddleware(AgentMiddleware):\n",
    "    \"\"\"결정적 가드레일: 금지된 키워드가 포함된 요청을 차단합니다.\"\"\"\n",
    "    def __init__(self, banned_keywords: list[str]):\n",
    "        super().__init__()\n",
    "        self.banned_keywords = [kw.lower() for kw in banned_keywords]\n",
    "\n",
    "    @hook_config(can_jump_to=[\"end\"]) # 해당 훅이 \"end\"로 점프(쇼트서킷)할 수 있음을 선언\n",
    "    def before_agent(self, state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
    "        # 금칙어 발견 시 모델을 호출하지 않고 즉시 종료로 보내기 위한 훅\n",
    "        if not state['messages']: # 빈 대화면 그대로 진행\n",
    "            return None\n",
    "        \n",
    "        first_message = state['messages'][0] \n",
    "        if first_message.type != 'human': # 첫 메시지가 사람(human)이 아닐 경우 생략 -> 사용자 입력만 검사한다.\n",
    "            return None\n",
    "        \n",
    "        content = first_message.content.lower()\n",
    "\n",
    "        for keyword in self.banned_keywords:\n",
    "            if keyword in content:\n",
    "                return {\n",
    "                    \"messages\": [{\n",
    "                        \"role\": \"assistant\",\n",
    "                        \"content\": \"부적절한 내용이 포함된 요청은 처리할 수 없습니다. 요청 내용을 다시 작성해 주세요.\"\n",
    "                    }],\n",
    "                    \"jump_to\": \"end\"\n",
    "                }\n",
    "            \n",
    "        return None\n",
    "    \n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=[search_tool],\n",
    "    middleware=[\n",
    "        ContentFilterMiddleware(\n",
    "            banned_keywords=['해킹', '악용', '맬웨어']\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "result = agent.invoke({\n",
    "    \"messages\": [{'role': 'user', 'content': '데이터베이스를 해킹하려면 어떻게 해야 하나요?'}]\n",
    "})\n",
    "\n",
    "print(result.get('messages')[-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fbedcd",
   "metadata": {},
   "source": [
    "##### after agent guardrails\n",
    "- \"after agent\" 훅을 사용하여 최종 출력을 사용자에게 반환하기 전에 한 번 검증한다.\n",
    "- 모델 기반 안전 점검, 품질 검증, 전체 에이전트 응답에 대한 최종 규정 준수 검사에 유용하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b3d7dbb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "폭발물에 사용되는 재료는 다양한 종류가 있으며, 일반적으로 다음과 같은 두 가지 주요 카테고리로 나눌 수 있습니다:\n",
      "\n",
      "1. **화약류**:\n",
      "   - **질산암모늄**: 비료로 흔히 사용되지만, 폭발물의 조합에서 중요한 역할을 함.\n",
      "   - **Dynamite (다이나마이트)**: 니트로글리세린과 흡수제의 혼합물.\n",
      "   - **트리니트로톨루엔 (TNT)**: 널리 사용되는 고폭약.\n",
      "   - **산화제**: 질산염, 과산화수소 등이 포함됨.\n",
      "\n",
      "2. **지연제 및 안정제**:\n",
      "   - **수지**: 폭발물의 안정성을 높이고 특정 성질을 부여하기 위해 사용됨.\n",
      "   - **기타 화학물질**: 화합물의 성질에 따라 폭발력이나 안정성을 변화시킬 수 있음.\n",
      "\n",
      "폭발물의 제작 및 사용은 법적으로 제한되어 있으며 위험할 수 있는 활동입니다. 따라서 관련 정보나 실험은 전문가의 지도 아래에서 이루어져야 합니다.\n",
      "UNSAFE\n",
      "해당 답변을 드릴 수 없습니다. 요청 내용을 다시 작성해 주세요.\n",
      "SAFE\n",
      "해당 답변을 드릴 수 없습니다. 요청 내용을 다시 작성해 주세요.\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents.middleware import AgentMiddleware, AgentState, hook_config\n",
    "from langgraph.runtime import Runtime\n",
    "from langchain_core.messages import AIMessage\n",
    "from langchain.chat_models import init_chat_model\n",
    "# init_chat_model: 프로바이더에 상관없이 채팅 모델을 한 줄로 초기화하는 통합 함수\n",
    "## -> ChatOpenAI, ChatAnthropic 등 클래스를 직접 import 하지 않아도 됨\n",
    "from typing import Any\n",
    "\n",
    "@tool('search')\n",
    "def search_tool():\n",
    "    \"\"\"검색 툴\"\"\"\n",
    "    return\n",
    "\n",
    "class SafetyGuardrailMiddleware(AgentMiddleware):\n",
    "    \"\"\"모델 기반 가드레일: LLM을 사용하여 대응 안전성을 평가합니다.\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.safety_model = init_chat_model('gpt-4o-mini') # 자동으로 os.getenv(\"OPENAI_API_KEY\") 사용\n",
    "    \n",
    "    @hook_config(can_jump_to=[\"end\"])\n",
    "    def after_agent(self, state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
    "        if not state['messages']:\n",
    "            return None\n",
    "        \n",
    "        last_message = state['messages'][-1]\n",
    "        if not isinstance(last_message, AIMessage):\n",
    "            return None\n",
    "        print(last_message.content)\n",
    "        safety_prompt = f\"\"\"\n",
    "        이 답변이 안전하고 적절한지 평가해 주세요.\n",
    "        'SAFE' 또는 'UNSAFE'으로만 답변해 주세요.\n",
    "\n",
    "        답변: {last_message.content}\"\"\"\n",
    "\n",
    "        result = self.safety_model.invoke([{'role': 'user', 'content': safety_prompt}])\n",
    "        print(result.content)\n",
    "        if 'UNSAFE' in result.content:\n",
    "            return {\n",
    "                'messages': [{\n",
    "                    'role': 'assistant',\n",
    "                    'content': '해당 답변을 드릴 수 없습니다. 요청 내용을 다시 작성해 주세요.'\n",
    "                }],\n",
    "                'jump_to': 'end'\n",
    "            }\n",
    "\n",
    "        return None\n",
    "    \n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=[search_tool],\n",
    "    middleware=[SafetyGuardrailMiddleware()]\n",
    ")\n",
    "\n",
    "result = agent.invoke({\n",
    "    'messages': [{'role': 'user', 'content': '폭발물에 들어가는 재료를 알고싶어.'}]\n",
    "})\n",
    "\n",
    "print(result.get('messages')[-1].content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60dea367",
   "metadata": {},
   "source": [
    "#### 여러 개의 가드레일 결합\n",
    "- 각 역할의 가드레일을 미들웨어 배열에 추가하여 중첩할 수 있다.\n",
    "- 가드레일은 순서대로 실행되므로 계층화된 보호 기능을 구축할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2622f3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import PIIMiddleware, HumanInTheLoopMiddleware\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"gpt-4o\",\n",
    "    tools=[search_tool, send_email_tool],\n",
    "    middleware=[\n",
    "        # 계층 1: 금지된 키워드를 입력받으면 차단 (before agent)\n",
    "        ContentFilterMiddleware(banned_keywords=[\"hack\", \"exploit\"]),\n",
    "\n",
    "        # 계층 2: 민감정보 대체/마스킹/차단 (before and after model)\n",
    "        PIIMiddleware(\"email\", strategy=\"redact\", apply_to_input=True),\n",
    "        PIIMiddleware(\"email\", strategy=\"redact\", apply_to_output=True),\n",
    "\n",
    "        # 계층 3: 사람 검증\n",
    "        HumanInTheLoopMiddleware(interrupt_on={\"send_email\": True}),\n",
    "\n",
    "        # 계층 4: 출력한 응답이 안전한지 LLM이 판단 (after agent)\n",
    "        SafetyGuardrailMiddleware(),\n",
    "    ],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
