{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a047674",
   "metadata": {},
   "source": [
    "### ëª©ì \n",
    "- LLMì´ ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆë„ë¡ ì •ë³´ì™€ ë„êµ¬ë¥¼ ì ì ˆí•œ í˜•ì‹ìœ¼ë¡œ ì œê³µí•˜ëŠ” ë™ì  ì‹œìŠ¤í…œ êµ¬ì¶•"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29bc611",
   "metadata": {},
   "source": [
    "#### ì»¨í…ìŠ¤íŠ¸ ì—”ì§€ë‹ˆì–´ë§ vs í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§\n",
    "| êµ¬ë¶„    | í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§                 | ì»¨í…ìŠ¤íŠ¸ ì—”ì§€ë‹ˆì–´ë§                                        |\n",
    "| ----- | -------------------------- | ------------------------------------------------- |\n",
    "| ì´ˆì     | í•œ ë²ˆì˜ ì…ë ¥ë¬¸ ì„¤ê³„                | ì „ì²´ ëŒ€í™”Â·ìƒíƒœÂ·í™˜ê²½ì˜ êµ¬ì¡° ì„¤ê³„                                |\n",
    "| ë‹¨ìœ„    | ë¬¸ìì—´ prompt                 | êµ¬ì¡°í™”ëœ context object                               |\n",
    "| ì ‘ê·¼ ë°©ì‹ | â€œì–´ë–»ê²Œ ë¬¼ì–´ë³¼ê¹Œ?â€                | â€œë¬´ì—‡ì„ ì•Œê³ , ì–´ë–¤ ìƒí™©ì—ì„œ ëŒ€ë‹µí•´ì•¼ í•˜ë‚˜?â€                        |\n",
    "| ì£¼ìš” ê¸°ìˆ  | few-shot, CoT, role prompt | context_schema, dynamic_prompt, middleware, state |\n",
    "| ê²°ê³¼    | ì¦‰ì‹œ í’ˆì§ˆ í–¥ìƒ                   | ì§€ì†ì  ì¼ê´€ì„±, ê°œì¸í™”, ë©€í‹°í„´ ì •í™•ë„                             |\n",
    "| ë¹„ìœ     | ë¬¸ì¥ ê¸°ìˆ                       | ì‹œìŠ¤í…œ ì„¤ê³„                                            |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd60c17",
   "metadata": {},
   "source": [
    "#### ì»¨í…ìŠ¤íŠ¸ ì¢…ë¥˜\n",
    "| ì»¨í…ìŠ¤íŠ¸ ì¢…ë¥˜                | ëª©ì                                       | ì–´ë””ì— ì €ì¥ë˜ë‚˜   | ì§€ì† ì‹œê°„                |\n",
    "| ---------------------- | --------------------------------------- | ---------- | -------------------- |\n",
    "| **Model Context**      | ëª¨ë¸ì—ê²Œ ì£¼ëŠ” ì¼ì‹œì  ì •ë³´ (í”„ë¡¬í”„íŠ¸, ë©”ì‹œì§€, íˆ´ ëª©ë¡ ë“±)      | ìš”ì²­ ë‚´ë¶€      | ğŸ”¹ì§§ìŒ (í•œ ë²ˆ í˜¸ì¶œìš©)       |\n",
    "| **Tool Context**       | íˆ´ í•¨ìˆ˜ê°€ ì½ê³  ì“¸ ìˆ˜ ìˆëŠ” í™˜ê²½(context/state/store) | Runtime ê°ì²´ | ğŸ”¸ì¤‘ê°„ (ì„¸ì…˜ ë‚´ ìœ ì§€)       |\n",
    "| **Life-cycle Context** | ì‹¤í–‰ ì „í›„ ê°ì‹œÂ·ì œì–´ìš© (ë¯¸ë“¤ì›¨ì–´, ìš”ì•½, ê²€ì—´ ë“±)           | ë¯¸ë“¤ì›¨ì–´ ê³„ì¸µ    | ğŸ”¸ì§€ì† (ì—¬ëŸ¬ í˜¸ì¶œ ê°„ ìœ ì§€ ê°€ëŠ¥) |\n",
    "\n",
    "- Model Context: ë§¤ í˜¸ì¶œë§ˆë‹¤ ìƒˆë¡œ ìƒì„± (Transient)\n",
    "- Tool/Life-cycle Context: ì‹¤í–‰ ì¤‘ í˜¹ì€ ì¥ê¸°ì ìœ¼ë¡œ ìœ ì§€ (Persistent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff02a5c",
   "metadata": {},
   "source": [
    "#### ì»¨í…ìŠ¤íŠ¸ ë°ì´í„° êµ¬ì„±\n",
    "- context: í˜„ì¬ ì‚¬ìš©ìë‚˜ í™˜ê²½ê°™ì€ ê³ ì • ì •ë³´\n",
    "    - ex) user_id, language, timezone\n",
    "- state: ëŒ€í™” ì¤‘ ì ê¹ ìœ ì§€ë˜ëŠ” ë‹¨ê¸° ë©”ëª¨ë¦¬\n",
    "    - ex) ì§ì „ ë©”ì‹œì§€, ì—…ë¡œë“œ íŒŒì¼ ìš”ì•½\n",
    "- store: ì¥ê¸° ë©”ëª¨ë¦¬\n",
    "    - ex) ì‚¬ìš©ì ì„ í˜¸, ê³¼ê±° ëŒ€í™” ìš”ì•½, ì˜êµ¬ ê¸°ë¡"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763ad288",
   "metadata": {},
   "source": [
    "#### ê° ì»¨í…ìŠ¤íŠ¸ ë³„ë¡œ ë‹¤ë£¨ëŠ” ë°ì´í„° ì†ŒìŠ¤\n",
    "| ì»¨íŠ¸ë¡¤ ê³„ì¸µ                 | ì½ëŠ” ë°ì´í„°                      | ì“°ëŠ” ë°ì´í„°          | ì£¼ìš” ì ‘ê·¼ ë°©ì‹                                                 | ë¹„ê³           |\n",
    "| ---------------------- | --------------------------- | --------------- | -------------------------------------------------------- | ----------- |\n",
    "| **Model Context**      | `context`, `state`, `store` | âŒ (ì½ê¸° ì¤‘ì‹¬)       | `request.context`, `request.state`, `request.store`      | ëª¨ë¸ í˜¸ì¶œ ì§ì „/ì§í›„ |\n",
    "| **Tool Context**       | `state`, `store`            | âœ… (Commandë¡œ ê°±ì‹ ) | `runtime.state`, `runtime.store`                         | íˆ´ í•¨ìˆ˜ ë‚´ ì‹¤í–‰   |\n",
    "| **Life-cycle Context** | `state`, `store`            | âœ… (ìš”ì•½/ê¸°ë¡)       | `before_model`, `after_model`, `SummarizationMiddleware` | ëŒ€í™” ê´€ë¦¬/ì••ì¶•    |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8027d369",
   "metadata": {},
   "source": [
    "#### Model Context ì¡°ì‘ ê¸°ë²• - System prompt\n",
    "- @dynamic_prompt\n",
    "    - ì‹¤í–‰ ì‹œì ì— state, runtime.context, runtime.storeë¥¼ ì½ì–´ system promptë¥¼ ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dbe9056a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â–¶ ì§§ì€ ëŒ€í™”:\n",
      "1\n",
      "ì¸ê³µì§€ëŠ¥(AI, Artificial Intelligence)ì€ ê¸°ê³„ë‚˜ ì»´í“¨í„° ì‹œìŠ¤í…œì´ ì¸ê°„ì˜ ì§€ëŠ¥ì„ ëª¨ë°©í•˜ê±°ë‚˜ ì´ë¥¼ ë„˜ì–´ì„œê¸° ìœ„í•´ ì„¤ê³„ëœ ê¸°ìˆ ê³¼ ì•Œê³ ë¦¬ì¦˜ì„ ì˜ë¯¸í•©ë‹ˆë‹¤. ì¸ê³µì§€ëŠ¥ì€ ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ í™œìš©ë˜ë©°, ê¸°ë³¸ì ìœ¼ë¡œ ì‚¬ëŒì²˜ëŸ¼ í•™ìŠµí•˜ê³ , ë¬¸ì œë¥¼ í•´ê²°í•˜ê³ , ì˜ì‚¬ ê²°ì •ì„ ë‚´ë¦¬ëŠ” ëŠ¥ë ¥ì„ ê°€ì§€ë„ë¡ ê°œë°œë©ë‹ˆë‹¤.\n",
      "\n",
      "AIëŠ” í¬ê²Œ ë‘ ê°€ì§€ ì£¼ìš” ë²”ì£¼ë¡œ ë‚˜ëˆŒ ìˆ˜ ìˆìŠµë‹ˆë‹¤:\n",
      "\n",
      "1. **í˜‘ì˜ì˜ ì¸ê³µì§€ëŠ¥(Narrow AI)**: íŠ¹ì • ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” ë° íŠ¹í™”ëœ AIì…ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì´ë¯¸ì§€ ì¸ì‹, ìì—°ì–´ ì²˜ë¦¬, ìŒì„± ì¸ì‹, ê²Œì„ í”Œë ˆì´ ë“± íŠ¹ì •í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ë° ë§¤ìš° ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ëƒ…ë‹ˆë‹¤. ì´ëŸ¬í•œ AIëŠ” ìš°ë¦¬ê°€ ì¼ìƒì—ì„œ í”íˆ ì‚¬ìš©í•˜ëŠ” ì±—ë´‡ì´ë‚˜ ì¶”ì²œ ì‹œìŠ¤í…œ ë“±ì— ë§ì´ ì‚¬ìš©ë©ë‹ˆë‹¤.\n",
      "\n",
      "2. **ì¼ë°˜ ì¸ê³µì§€ëŠ¥(General AI)**: ì¸ê°„ê³¼ ê°™ì€ ìˆ˜ì¤€ì˜ ì§€ëŠ¥ì„ ê°€ì§€ë©°, ì—¬ëŸ¬ ê°€ì§€ ì¢…ë¥˜ì˜ ì‘ì—…ì„ ì´í•´í•˜ê³  ìˆ˜í–‰í•  ìˆ˜ ìˆëŠ” AIë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤. í˜„ì¬ ì¼ë°˜ ì¸ê³µì§€ëŠ¥ì€ ì•„ì§ ê°œë°œë˜ì§€ ì•Šì•˜ì§€ë§Œ, ì´ëŠ” ë¯¸ë˜ì˜ ëª©í‘œ ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤.\n",
      "\n",
      "ì¸ê³µì§€ëŠ¥ì˜ ì£¼ìš” êµ¬ì„± ìš”ì†Œë¡œëŠ” ê¸°ê³„ í•™ìŠµ(Machine Learning), ë”¥ ëŸ¬ë‹(Deep Learning), ìì—°ì–´ ì²˜ë¦¬(Natural Language Processing) ë“±ì´ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "- **ê¸°ê³„ í•™ìŠµ**: ë°ì´í„°ë¥¼ í†µí•´ í•™ìŠµí•˜ì—¬ ì˜ˆì¸¡í•˜ê±°ë‚˜ ê²°ì •ì„ ë‚´ë¦¬ëŠ” ì•Œê³ ë¦¬ì¦˜ì…ë‹ˆë‹¤. ë°ì´í„°ê°€ ë§ì„ìˆ˜ë¡ ë” ë‚˜ì€ ì˜ˆì¸¡ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "- **ë”¥ ëŸ¬ë‹**: ì¸ê³µ ì‹ ê²½ë§(Artificial Neural Networks)ì˜ ë°œì „ëœ í˜•íƒœë¡œ, ëŒ€ëŸ‰ì˜ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ê³  ë³µì¡í•œ íŒ¨í„´ì„ ì¸ì‹í•˜ëŠ” ë° ê°•ë ¥í•œ ì„±ëŠ¥ì„ ë°œíœ˜í•©ë‹ˆë‹¤.\n",
      "- **ìì—°ì–´ ì²˜ë¦¬**: ì»´í“¨í„°ê°€ ì¸ê°„ì˜ ì–¸ì–´ë¥¼ ì´í•´í•˜ê³  í•´ì„í•˜ëŠ” ê¸°ìˆ ë¡œ, ì¸ê°„ê³¼ì˜ ì˜ì‚¬ì†Œí†µì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.\n",
      "\n",
      "ì¸ê³µì§€ëŠ¥ì€ ì˜ë£Œ, ê¸ˆìœµ, ì œì¡°, ììœ¨ì£¼í–‰ ì°¨ëŸ‰, êµìœ¡ ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ í™œìš©ë˜ë©°, ë¯¸ë˜ ì‚¬íšŒì— í° ì˜í–¥ì„ ë¯¸ì¹  ê²ƒìœ¼ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤. \n",
      "\n",
      "â–¶ ê¸´ ëŒ€í™”:\n",
      "7\n",
      "ì¸ê³µì§€ëŠ¥(AI)ì€ ê¸°ê³„ë‚˜ ì†Œí”„íŠ¸ì›¨ì–´ê°€ ì¸ê°„ì²˜ëŸ¼ í•™ìŠµ, ì¶”ë¡ , ë¬¸ì œ í•´ê²°ì„ í•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# state ì‚¬ìš© ì˜ˆì‹œ ì½”ë“œ\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import dynamic_prompt, ModelRequest\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "@dynamic_prompt\n",
    "def system_prompt_selector(request: ModelRequest) -> str:\n",
    "    \"\"\"\n",
    "    í˜„ì¬ ëŒ€í™” ê¸¸ì´ì— ë”°ë¼ system promptë¥¼ ìë™ ë³€ê²½í•œë‹¤.\n",
    "    - ë©”ì‹œì§€ê°€ ë§ìœ¼ë©´: ê°„ê²°í•˜ê²Œ\n",
    "    - ë©”ì‹œì§€ê°€ ì ìœ¼ë©´: ì¼ë°˜ ëª¨ë“œ\n",
    "    \"\"\"\n",
    "    # request.state[\"messages\"] ë¥¼ request.messages ë¡œ ì¤„ì—¬ì„œ ì ì„ ìˆ˜ ìˆë‹¤. -> ìµœì‹  ë²„ì „ ê¶Œì¥ì€ ì¶•ì•½ í˜•íƒœ\n",
    "    # message_count = len(request.messages)\n",
    "    message_count = len(request.state[\"messages\"])\n",
    "    print(len(request.state[\"messages\"]))\n",
    "    base = \"ë„ˆëŠ” ìœ ìš©í•œ ì–´ì‹œìŠ¤í„´íŠ¸ì´ë‹¤.\"\n",
    "    if message_count > 5:\n",
    "        base += \"\\nëŒ€í™”ê°€ ê¸¸ì–´ì¡Œìœ¼ë‹ˆ ê°„ê²°í•˜ê²Œ ë‹µë³€í•´ë¼.\"\n",
    "    else:\n",
    "        base += \"\\nìƒì„¸í•˜ê³  ì¹œì ˆí•˜ê²Œ ì„¤ëª…í•´ë¼.\"\n",
    "    return base\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=[],  \n",
    "    middleware=[system_prompt_selector]\n",
    ")\n",
    "\n",
    "conversation_short = {\"messages\": [{\"role\": \"user\", \"content\": \"ì¸ê³µì§€ëŠ¥ì´ ë­ì•¼?\"}]}\n",
    "conversation_long = {\"messages\": [{\"role\": \"user\", \"content\": \"ì¸ê³µì§€ëŠ¥ì´ ë­ì•¼?\"} for i in range(7)]}\n",
    "\n",
    "print(\"â–¶ ì§§ì€ ëŒ€í™”:\")\n",
    "result_short = agent.invoke(conversation_short)\n",
    "print(result_short[\"messages\"][-1].content, \"\\n\")\n",
    "\n",
    "print(\"â–¶ ê¸´ ëŒ€í™”:\")\n",
    "result_long = agent.invoke(conversation_long)\n",
    "print(result_long[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7d6f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user id: u-001\n",
      "ì¸ê³µì§€ëŠ¥ì€ ì¸ê°„ì˜ ì§€ëŠ¥ì„ ëª¨ë°©í•˜ê±°ë‚˜ ëŒ€ì²´í•  ìˆ˜ ìˆëŠ” ì»´í“¨í„° ì‹œìŠ¤í…œì´ë‚˜ í”„ë¡œê·¸ë¨ì´ì•¼. ì£¼ë¡œ í•™ìŠµ, ë¬¸ì œ í•´ê²°, íŒ¨í„´ ì¸ì‹ ê°™ì€ ê¸°ëŠ¥ì„ í†µí•´ ë°ì´í„°ì—ì„œ í†µì°°ì„ ì–»ê³  ì˜ì‚¬ ê²°ì •ì„ ë‚´ë¦¬ëŠ” ë° ì‚¬ìš©ë¼.\n"
     ]
    }
   ],
   "source": [
    "# runtime.contextì™€ runtime.store ì‚¬ìš© ì˜ˆì‹œ ì½”ë“œ\n",
    "\n",
    "import os\n",
    "from dataclasses import dataclass\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import dynamic_prompt, ModelRequest\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "@dataclass\n",
    "class Context:\n",
    "    user_id: str\n",
    "\n",
    "# ì¥ê¸° ìŠ¤í† ì–´ ì¤€ë¹„\n",
    "store = InMemoryStore()\n",
    "store.put((\"preferences\",), \"u-001\", {\"communication_style\": \"ë°˜ë§\"})\n",
    "\n",
    "# ë™ì  ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸: context.user_idë¡œ store ì¡°íšŒ\n",
    "@dynamic_prompt\n",
    "def store_aware_prompt(request: ModelRequest) -> str:\n",
    "    user_id = request.runtime.context.user_id # ëŸ°íƒ€ì„ì—ì„œ contextë¡œ ë“¤ì–´ì˜¨ user_id\n",
    "    print(\"user id:\", user_id)\n",
    "    item = request.runtime.store.get((\"preferences\",), user_id) # ì¥ê¸° ë©”ëª¨ë¦¬ì—ì„œ user_idë¡œ ì„ í˜¸ ê²€ìƒ‰\n",
    "    base = \"ë„ˆëŠ” ìœ ìš©í•œ ì¡°ìˆ˜ì´ë‹¤.\"\n",
    "    if item:\n",
    "        style = item.value.get(\"communication_style\", \"ê· í˜•ì¡íŒ ì–´íˆ¬\")\n",
    "        base += f\"\\nìœ ì €ì˜ ì„ í˜¸ë„ëŠ” {style} ì´ë‹¤.\"\n",
    "    return base\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=[],\n",
    "    middleware=[store_aware_prompt],\n",
    "    context_schema=Context,\n",
    "    store=store,\n",
    ")\n",
    "\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"ê°„ë‹¨íˆ ìš”ì•½í•´ì„œ ì¸ê³µì§€ëŠ¥ ì •ì˜í•´ì¤˜\"}]},\n",
    "    context=Context(user_id=\"u-001\"),\n",
    ")\n",
    "\n",
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb06dabf",
   "metadata": {},
   "source": [
    "#### Model Context ì¡°ì‘ ê¸°ë²• - Messages\n",
    "- @wrap_model_call\n",
    "    - ëª¨ë¸ì— ì‹¤ì œë¡œ ë“¤ì–´ê°€ëŠ” ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ë¥¼ ì¡°ì‘ -> ëª¨ë¸ ì…ë ¥ì„ ì§ì „ì— ë‹¤ë“¬ì–´ ì •í™•ë„, ì•ˆì „ì„±, í† í° íš¨ìœ¨ì„ ë†’ì¸ë‹¤.(ìš”ì•½, ì •ë¦¬, í•„í„°ë§, ì»¨í…ìŠ¤íŠ¸ ì£¼ì… ë“±)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebb8535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìµœê·¼ ë¡œê·¸ë¥¼ í™•ì¸í•´ë³´ê² ìŠµë‹ˆë‹¤. ì£¼ì–´ì§„ `error_log.txt` íŒŒì¼ì„ ì°¸ê³ í•˜ì—¬ ì„œë¹„ìŠ¤ ì¥ì• ì˜ ì›ì¸ì„ ìš”ì•½í•˜ê² ìŠµë‹ˆë‹¤. \n",
      "\n",
      "íŒŒì¼ì„ ì—´ì–´ë´ì•¼ í•  ë‚´ìš©ì´ë¯€ë¡œ, ì§ì ‘ì ìœ¼ë¡œ ë‚´ìš©ì„ ë¶„ì„í•  ìˆ˜ëŠ” ì—†ì§€ë§Œ, ì¼ë°˜ì ìœ¼ë¡œ ì—ëŸ¬ ë¡œê·¸ì—ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ì •ë³´ê°€ í¬í•¨ë˜ì–´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤:\n",
      "\n",
      "1. **íƒ€ì„ìŠ¤íƒ¬í”„**: ì—ëŸ¬ê°€ ë°œìƒí•œ ì‹œê°.\n",
      "2. **ì—ëŸ¬ ì½”ë“œ**: ì–´ë–¤ ì¢…ë¥˜ì˜ ì—ëŸ¬ì¸ì§€ ì•Œ ìˆ˜ ìˆëŠ” ì½”ë“œ.\n",
      "3. **ë©”ì‹œì§€**: ì—ëŸ¬ì— ëŒ€í•œ ìƒì„¸ ì„¤ëª….\n",
      "4. **ë°œìƒ ìœ„ì¹˜**: ì½”ë“œì˜ ì–´ë–¤ ë¶€ë¶„ì—ì„œ ë¬¸ì œê°€ ë°œìƒí–ˆëŠ”ì§€.\n",
      "\n",
      "ì´ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœê·¼ ì—ëŸ¬ê°€ ë°œìƒí•œ ì‹œê°, ì—ëŸ¬ ì¢…ë¥˜, ì—ëŸ¬ ë©”ì‹œì§€ ë“±ì„ ì¢…í•©í•˜ì—¬ ì¥ì• ì˜ ì›ì¸ì„ ë¶„ì„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ì§ì ‘ì ì¸ ì›ì¸ ë¶„ì„ì´ í•„ìš”í•˜ì‹œë©´ í•´ë‹¹ `error_log.txt` íŒŒì¼ì˜ ë‚´ìš©ì„ ì§ì ‘ í™•ì¸í•´ì£¼ì‹œë©´, ë” êµ¬ì²´ì ìœ¼ë¡œ ë„ì›€ì„ ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì¶”ê°€ì ìœ¼ë¡œ ê¶ê¸ˆí•œ ì‚¬í•­ì´ ìˆìœ¼ë©´ ë§ì”€í•´ ì£¼ì„¸ìš”.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import Callable, List, Dict, Any\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import wrap_model_call, ModelRequest, ModelResponse\n",
    "from langchain.agents import AgentState\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "class MyState(AgentState):\n",
    "    uploaded_files: List[Dict[str, Any]]\n",
    "\n",
    "@wrap_model_call\n",
    "def inject_file_context(\n",
    "    request: ModelRequest,\n",
    "    handler: Callable[[ModelRequest], ModelResponse]\n",
    ") -> ModelResponse:\n",
    "    \"\"\"ì´ ì„¸ì…˜ì—ì„œ ì‚¬ìš©ìê°€ ì—…ë¡œë“œí•œ íŒŒì¼ì— ëŒ€í•œ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì‚½ì…í•©ë‹ˆë‹¤.\"\"\"\n",
    "    uploaded_files_state: List[Dict[str, Any]] = request.state.get('uploaded_files', [])\n",
    "    \n",
    "    if uploaded_files_state:\n",
    "        file_description = [\n",
    "            f\"{f['name']} ({f['type']}): {f['summary']}\"\n",
    "            for f in uploaded_files_state\n",
    "        ]\n",
    "\n",
    "        file_context = (\n",
    "            \"ì´ ëŒ€í™”ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ íŒŒì¼:\\n\"\n",
    "            + \"\\n\".join(file_description)\n",
    "            + \"\\në‹µë³€í•  ë•Œ ì´ê²ƒì„ ì°¸ê³  ìë£Œë¡œ í™œìš©í•˜ì„¸ìš”.\"\n",
    "        )\n",
    "\n",
    "        augmented_messages = [\n",
    "            {'role': 'system', 'content': file_context},\n",
    "            *request.messages # ìŠ¤í”„ë ˆë“œ(unpack) ë¬¸ë²• -> request.messagesì„ í’€ì–´ì„œ ë’¤ì— ì´ì–´ë¶™ì„\n",
    "        ]\n",
    "\n",
    "        request = request.override(messages=augmented_messages) # ìˆ˜ì •í•œ messagesë¥¼ êµì²´í•œë‹¤.\n",
    "        # override()ë¥¼ ì¨ì•¼í•˜ëŠ” ì´ìœ ?\n",
    "        # ModelRequest ê°ì²´ëŠ” ë¶ˆë³€(immutable)ì´ë¼ì„œ request.messages=... ë¡œ ìˆ˜ì •í•  ìˆ˜ ì—†ë‹¤.\n",
    "    \n",
    "    return handler(request)\n",
    "\n",
    "uploaded_files_state = [\n",
    "    {\"name\": \"project_plan.pdf\", \"type\": \"pdf\", \"summary\": \"Q4 ë§ˆì¼ìŠ¤í†¤/ë°ë“œë¼ì¸ ìš”ì•½\"},\n",
    "    {\"name\": \"error_log.txt\", \"type\": \"text\", \"summary\": \"ìµœê·¼ ì—ëŸ¬ì™€ íƒ€ì„ìŠ¤íƒ¬í”„\"},\n",
    "]\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=[],\n",
    "    middleware=[inject_file_context],\n",
    "    state_schema=MyState\n",
    ")\n",
    "\n",
    "result = agent.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": \"ìµœê·¼ ë¡œê·¸ë¥¼ ì°¸ê³ í•´ì„œ ì„œë¹„ìŠ¤ ì¥ì•  ì›ì¸ ìš”ì•½í•´ì¤˜.\"}\n",
    "        ],\n",
    "        \"uploaded_files\": uploaded_files_state\n",
    "    },\n",
    ")\n",
    "\n",
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d0d57340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì•ˆë…•í•˜ì„¸ìš”, ê³ ê° Aë‹˜.\n",
      "\n",
      "ìµœê·¼ ë°œìƒí•œ ì¥ì• ì— ëŒ€í•œ ì›ì¸ê³¼ ì¬ë°œ ë°©ì§€ ì¡°ì¹˜ì— ëŒ€í•´ ì•ˆë‚´ë“œë¦½ë‹ˆë‹¤.\n",
      "\n",
      "ì¥ì• ì˜ ì£¼ìš” ì›ì¸ì€ ì‹œìŠ¤í…œ ë‚´ì—ì„œ ì˜ˆê¸°ì¹˜ ì•Šì€ ì˜¤ë¥˜ë¡œ ì¸í•œ ê²ƒì´ì—ˆìŠµë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ê³ ê°ë‹˜ì˜ ì„œë¹„ìŠ¤ì— ë¶ˆí¸ì„ ë“œë¦° ì  ì§„ì‹¬ìœ¼ë¡œ ì‚¬ê³¼ë“œë¦½ë‹ˆë‹¤. \n",
      "\n",
      "ì¬ë°œ ë°©ì§€ë¥¼ ìœ„í•´ ë‹¤ìŒê³¼ ê°™ì€ ì¡°ì¹˜ë¥¼ ì·¨í•  ì˜ˆì •ì…ë‹ˆë‹¤:\n",
      "1. ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§ ê°•í™”: ì˜¤ë¥˜ ë°œìƒ ì‹œ ì¦‰ì‹œ ì•Œë¦¼ì„ ë°›ì„ ìˆ˜ ìˆë„ë¡ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œì„ ê°œì„ í•˜ê² ìŠµë‹ˆë‹¤.\n",
      "2. ë²„ê·¸ ìˆ˜ì •: ì´ë²ˆ ì´ìŠˆì™€ ê´€ë ¨ëœ ì½”ë“œë¥¼ ì ê²€í•˜ê³  ìˆ˜ì •í•˜ì—¬ ìœ ì‚¬ ì‚¬ë¡€ê°€ ë°œìƒí•˜ì§€ ì•Šë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.\n",
      "3. ì •ê¸°ì ì¸ ì ê²€: í–¥í›„ ì •ê¸°ì ì¸ ì‹œìŠ¤í…œ ì ê²€ì„ ì‹¤ì‹œí•˜ì—¬ ë¬¸ì œë¥¼ ì‚¬ì „ì— ë°œê²¬í•  ìˆ˜ ìˆë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.\n",
      "\n",
      "í˜¹ì‹œ ì¶”ê°€ë¡œ ê¶ê¸ˆí•˜ì‹  ì‚¬í•­ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“ ì§€ ë§ì”€í•´ ì£¼ì„¸ìš”.\n",
      "\n",
      "ê°ì‚¬í•©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dataclasses import dataclass\n",
    "from typing import Callable\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import wrap_model_call, ModelRequest, ModelResponse\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "@dataclass\n",
    "class Context:\n",
    "    user_id: str\n",
    "\n",
    "@wrap_model_call\n",
    "def inject_writing_style(\n",
    "    request: ModelRequest,\n",
    "    handler: Callable[[ModelRequest], ModelResponse]\n",
    ") -> ModelResponse:\n",
    "    \"\"\"Inject user's email writing style from Store.\"\"\"\n",
    "    user_id = request.runtime.context.user_id\n",
    "\n",
    "    store = request.runtime.store\n",
    "    writing_style = store.get((\"writing_style\",), user_id)\n",
    "\n",
    "    if writing_style:\n",
    "        style = writing_style.value\n",
    "        style_context = f\"\"\"Your writing style:\n",
    "        - Tone: {style.get('tone', 'professional')}\n",
    "        - Typical greeting: \"{style.get('greeting', 'Hi')}\"\n",
    "        - Typical sign-off: \"{style.get('sign_off', 'Best')}\"\n",
    "        - Example email you've written:\n",
    "        {style.get('example_email', '')}\"\"\"\n",
    "        messages = [\n",
    "            *request.messages,\n",
    "            {\"role\": \"user\", \"content\": style_context}\n",
    "        ]\n",
    "        request = request.override(messages=messages)\n",
    "\n",
    "    return handler(request)\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# ì¥ê¸° ë©”ëª¨ë¦¬ ì¤€ë¹„\n",
    "store = InMemoryStore()\n",
    "store.put((\"writing_style\",), \"u-001\", {\n",
    "    \"tone\": \"friendly and concise\",\n",
    "    \"greeting\": \"ì•ˆë…•í•˜ì„¸ìš”\",\n",
    "    \"sign_off\": \"ê°ì‚¬í•©ë‹ˆë‹¤\",\n",
    "    \"example_email\": \"ì•ˆë…•í•˜ì„¸ìš”, ì–´ì œ ìš”ì²­ì£¼ì‹  ë¡œê·¸ ë¶„ì„ ê²°ê³¼ë¥¼ ê³µìœ ë“œë¦½ë‹ˆë‹¤. í•µì‹¬ ì›ì¸ì€ ...\",\n",
    "})\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=[],\n",
    "    middleware=[inject_writing_style],\n",
    "    context_schema=Context,\n",
    "    store=store,\n",
    ")\n",
    "\n",
    "result = agent.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": \"ê³ ê° Aì—ê²Œ ì¥ì•  ì›ì¸ê³¼ ì¬ë°œ ë°©ì§€ ì¡°ì¹˜ì— ëŒ€í•œ ì´ë©”ì¼ ì´ˆì•ˆ ì‘ì„±í•´ì¤˜.\"}\n",
    "        ]\n",
    "    },\n",
    "    context=Context(user_id=\"u-001\")\n",
    ")\n",
    "\n",
    "print(result[\"messages\"][-1].content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e625973",
   "metadata": {},
   "source": [
    "#### Model Context ì¡°ì‘ ê¸°ë²• - Tools\n",
    "- íˆ´ì—ëŠ” ëª…í™•í•œ ì´ë¦„, ì„¤ëª…, ì¸ìˆ˜ ì´ë¦„, ì¸ìˆ˜ ì„¤ëª…ì´ í•„ìš”í•˜ë‹¤. \n",
    "    - ë‹¨ìˆœíˆ ë©”íƒ€ë°ì´í„°ê°€ ì•„ë‹ˆë¼ LLMì´ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•œ ëª¨ë¸ì˜ ì¶”ë¡ ì„ ì•ˆë‚´í•˜ëŠ” ì—­í• ì´ë‹¤.\n",
    "- íˆ´ì´ ë„ˆë¬´ ë§ìœ¼ë©´ ëª¨ë¸ì— ê³¼ë¶€í•˜(ì»¨í…ìŠ¤íŠ¸ ê³¼ë¶€í•˜)ë¥¼ ì¼ìœ¼ì¼œ ì˜¤ë¥˜ê°€ ì¦ê°€í•˜ê³ , ë„êµ¬ê°€ ë„ˆë¬´ ì ìœ¼ë©´ ê¸°ëŠ¥ì´ ì œí•œëœë‹¤.\n",
    "    - ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ì„¸íŠ¸ë¥¼ ì¡°ì •í•˜ê¸° ìœ„í•´ Model Context(state, store, context)ë¥¼ ì´ìš©í•œë‹¤.\n",
    "    - ì˜ˆ) ì¸ì¦ ì „ì—ëŠ” public toolë§Œ ë…¸ì¶œ, ì¸ì¦ í›„ì—ëŠ” private tool í™œì„±í™” ë“±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4518a3bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
